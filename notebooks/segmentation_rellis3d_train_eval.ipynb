{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install required libs\n",
    "# !pip install -U segmentation-models-pytorch albumentations --user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from traversability_estimation.utils import visualize\n",
    "from traversability_estimation.rellis_3d import DatasetSemSeg as Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataloader\n",
    "\n",
    "Writing helper class for data extraction, tranformation and preprocessing  \n",
    "https://pytorch.org/docs/stable/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets look at data we have\n",
    "\n",
    "# ds = Dataset(classes=['grass', 'tree', 'sky'], split='train')\n",
    "# ds = Dataset(classes=['grass', 'tree', 'sky'], split='val')\n",
    "ds = Dataset(classes=['grass', 'tree', 'sky'], split='test')\n",
    "\n",
    "ind = int( np.random.choice(range(len(ds))) )\n",
    "image, mask = ds[ind] # get some sample\n",
    "image_vis = image * ds.std + ds.mean\n",
    "\n",
    "visualize(\n",
    "    image=image_vis, \n",
    "    grass_mask=mask[0, ...],\n",
    "    tree_mask=mask[1, ...],\n",
    "    sky_mask=mask[2, ...]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data augmentation is a powerful technique to increase the amount of your data and prevent model overfitting.  \n",
    "If you not familiar with such trick read some of these articles:\n",
    " - [The Effectiveness of Data Augmentation in Image Classification using Deep\n",
    "Learning](http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf)\n",
    " - [Data Augmentation | How to use Deep Learning when you have Limited Data](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)\n",
    " - [Data Augmentation Experimentation](https://towardsdatascience.com/data-augmentation-experimentation-3e274504f04b)\n",
    "\n",
    "Since our dataset is very small we will apply a large number of different augmentations:\n",
    " - horizontal flip\n",
    " - affine transforms\n",
    " - perspective transforms\n",
    " - brightness/contrast/colors manipulations\n",
    " - image bluring and sharpening\n",
    " - gaussian noise\n",
    " - random crops\n",
    "\n",
    "All this transforms can be easily applied with [**Albumentations**](https://github.com/albu/albumentations/) - fast augmentation library.\n",
    "For detailed explanation of image transformations you can look at [kaggle salt segmentation exmaple](https://github.com/albu/albumentations/blob/master/notebooks/example_kaggle_salt.ipynb) provided by [**Albumentations**](https://github.com/albu/albumentations/) authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_size = np.array(image.shape[:2])\n",
    "src_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize resulted augmented images and masks\n",
    "\n",
    "ds_aug = Dataset(split='train')\n",
    "\n",
    "# same image with different random transforms\n",
    "for i in range(3):\n",
    "    image, mask = ds_aug[1]\n",
    "    image_vis = image.transpose([1, 2, 0]) * ds_aug.std + ds_aug.mean\n",
    "    \n",
    "    visualize(image=image_vis, grass_mask=mask[2, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['void', 'dirt', 'grass', 'tree', 'pole', 'water',\n",
    "           'sky', 'vehicle', 'object', 'asphalt', 'building',\n",
    "           'log', 'person', 'fence', 'bush', 'concrete',\n",
    "           'barrier', 'puddle', 'mud', 'rubble']\n",
    "ACTIVATION = 'sigmoid' if len(CLASSES) == 1 else 'softmax2d'  # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "IMG_SIZE = (352, 640)\n",
    "LR = 0.0001\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(classes=CLASSES, crop_size=IMG_SIZE, split='train')\n",
    "valid_dataset = Dataset(classes=CLASSES, crop_size=IMG_SIZE, split='val')\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=12)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=LR),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "max_score = 0\n",
    "n_epochs = 10\n",
    "for i in range(0, n_epochs):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, './best_model.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "# best_model = torch.load('./best_model.pth')\n",
    "best_model = torch.load('../config/weights/smp/se_resnext50_32x4d_352x640_lr1e-4.pth')\n",
    "# best_model = torch.load('../config/weights/smp/mobilenet_v2_352x640_lr1e-4_iou_0.46.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from hrnet.core.function import convert_label, convert_color\n",
    "import yaml\n",
    "\n",
    "test_dataset = Dataset(classes=CLASSES, crop_size=(704, 960), split='test')\n",
    "\n",
    "cfg = yaml.safe_load(open('../config/rellis.yaml', 'r'))\n",
    "\n",
    "def mask_to_colormap(mask, cfg):\n",
    "    mask = np.argmax(mask, axis=0).astype(np.uint8)\n",
    "    mask = convert_label(mask, True)\n",
    "    mask = convert_color(mask, cfg[\"color_map\"])\n",
    "    return mask\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image, gt_mask = test_dataset[n]\n",
    "    image_vis = image * test_dataset.std + test_dataset.mean\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image.transpose([2, 0, 1])).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "    \n",
    "    pred_colormap = mask_to_colormap(pr_mask, cfg)\n",
    "    gt_colormap = mask_to_colormap(gt_mask, cfg)\n",
    "\n",
    "    visualize(image=image_vis, pred=pred_colormap, gt=gt_colormap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
