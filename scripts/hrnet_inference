#!/usr/bin/env python
from __future__ import absolute_import, division, print_function
import os
import cv2
import yaml
import torch
import rospy
import numpy as np
from hrnet.config import config
import matplotlib.pyplot as plt
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
from hrnet.core.function import convert_label, convert_color
from hrnet import models
from hrnet.utils.utils import draw_legend
from traversability_estimation.utils import normalize
from PIL import Image as pil
from time import time

pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))
RELLIS_CONFIG = os.path.join(pkg_path, "config/rellis.yaml")
RELLIS_CONFIG_TRAVERSABILITY = os.path.join(pkg_path, "config/rellis_traversability.yaml")
MODEL_CONFIG = os.path.join(pkg_path, "config/hrnet_rellis/"
                                      "seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml")
PRETRAINED_MODEL = os.path.join(pkg_path, "config/weights/"
                                          "seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484/best.pth")
DATASET_ROOT = os.path.join(pkg_path, "data/Rellis_3D/")


class ImageProcessor:
    """
    Class for image segmentations

    Args:
        compressed [bool] - for differentiation between compressed and uncompressed image messages
        number [int] - index of the image processor class <0,num_cameras)

    Topics:
        input_{number} - input image topic
        output_{number} - output segmented image topic
    """

    def __init__(self, number=1, image_transport='compressed', traversability_labels=True, device='cpu'):
        assert isinstance(number, int)
        assert image_transport == 'compressed' or image_transport == 'raw'
        assert isinstance(traversability_labels, bool)
        self.device = device
        self.bridge = CvBridge()
        self.model = self.load_model()
        self.model.eval().to(device=self.device)

        # Constants
        self.orig_size = None
        self.input_size = (1024, 512)
        self.mean = [0.485, 0.456, 0.406]
        self.std = [0.229, 0.224, 0.225]

        # Draw legend to segmentation
        if traversability_labels:
            self.data_cfg = yaml.safe_load(open(RELLIS_CONFIG_TRAVERSABILITY, 'r'))
        else:
            self.data_cfg = yaml.safe_load(open(RELLIS_CONFIG, 'r'))

        # Publishers
        self.semseg_pub = rospy.Publisher("output_%i/semseg/compressed" % number, CompressedImage, queue_size=1)
        self.caminfo_pub = rospy.Publisher("output_%i/camera_info" % number, CameraInfo, queue_size=1)

        # Subscribers
        self.caminfo_msg = None
        self.caminfo_sub = rospy.Subscriber("input_%i/camera_info" % number, CameraInfo, self.get_camera_info, queue_size=1)
        self.max_age = rospy.get_param('~max_age', 1.0)
        self.image_transport = image_transport
        message = CompressedImage if image_transport == 'compressed' else Image
        self.image_sub = rospy.Subscriber("input_%i/rgb" % number, message, self.callback_color, queue_size=1)

        # Info
        rospy.loginfo('Loaded CNN model number %i' % number)

    def get_camera_info(self, msg):
        """Store camera calibration for i-th camera."""
        assert isinstance(msg, CameraInfo)
        self.caminfo_msg = msg
        rospy.loginfo('Camera (%s) unsubscribed.' % msg.header.frame_id)
        self.caminfo_sub.unregister()

    def load_model(self):
        # Updates PATHS in model config file
        self._update_config(MODEL_CONFIG)

        # Create model
        config.defrost()
        config.merge_from_file(MODEL_CONFIG)
        config.merge_from_list(['TEST.MODEL_FILE', PRETRAINED_MODEL])
        config.freeze()
        model = eval('models.' + config.MODEL.NAME + '.get_seg_model')(config)

        pretrained_dict = torch.load(PRETRAINED_MODEL)
        if 'state_dict' in pretrained_dict:
            pretrained_dict = pretrained_dict['state_dict']
        model_dict = model.state_dict()
        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items()
                           if k[6:] in model_dict.keys()}
        model_dict.update(pretrained_dict)
        model.load_state_dict(model_dict)
        return model

    def callback_color(self, img_msg):
        age = (rospy.Time.now() - img_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Image message is too old for segmentation: %.3f' % age)
            return

        t0 = time()
        try:
            if self.image_transport:
                image = self.bridge.compressed_imgmsg_to_cv2(img_msg, "bgr8")
            else:
                image = self.bridge.imgmsg_to_cv2(img_msg, "bgr8")
        except CvBridgeError as e:
            rospy.logerr(e)
            return

        if self.orig_size is None:
            self.orig_size = (image.shape[1], image.shape[0])
            rospy.loginfo('Original image size: %s', self.orig_size)

        image = self.preprocessing(image)
        with torch.no_grad():
            pred = self.model(torch.from_numpy(image).unsqueeze(0).to(self.device))
            result = self.postprocessing(pred)
            rospy.logdebug('Image of size %s processing took: %.3f sec' % (image.shape, time() - t0))

        try:
            res_msg = CompressedImage()
            res_msg.header.stamp = img_msg.header.stamp
            res_msg.header.frame_id = img_msg.header.frame_id
            res_msg.format = "jpeg"
            res_msg.data = np.array(cv2.imencode('.jpg', result)[1]).tobytes()
            self.semseg_pub.publish(res_msg)
        except CvBridgeError as e:
            rospy.logerr(e)
        # publish camera info
        if self.caminfo_msg:
            self.caminfo_msg.header.stamp = img_msg.header.stamp
            self.caminfo_msg.header.frame_id = img_msg.header.frame_id
            self.caminfo_pub.publish(self.caminfo_msg)
        else:
            rospy.logwarn('Camera info synchronized with semseg predictions is not being published')

    def preprocessing(self, image):
        image = cv2.resize(image, self.input_size, interpolation=cv2.INTER_LINEAR)
        image = image.astype(np.float32)[:, :, ::-1]
        image = image / 255.0
        image -= self.mean
        image /= self.std
        image = image.transpose((2, 0, 1))
        return image

    def postprocessing(self, pred):
        pred = pred[config.TEST.OUTPUT_INDEX]
        pred_np = pred.squeeze(0).cpu().numpy()
        pred_arg = np.argmax(pred_np, axis=0).astype(np.uint8)
        pred_arg = convert_label(pred_arg, True)
        result = convert_color(pred_arg, self.data_cfg["color_map"])
        result = cv2.resize(result, self.orig_size, interpolation=cv2.INTER_LINEAR)
        return np.asarray(result)[..., (2, 1, 0)]

    def _update_config(self, config_path):
        assert isinstance(config_path, str)
        with open(config_path, 'r') as f:
            cfg = yaml.safe_load(f)
        cfg['DATASET']['ROOT'] = DATASET_ROOT
        cfg['MODEL']['PRETRAINED'] = PRETRAINED_MODEL
        with open(config_path, 'w') as f:
            yaml.dump(cfg, f)


def main():
    rospy.init_node('hrnet_inference', log_level=rospy.DEBUG)

    # Load parameters
    device = rospy.get_param("~device", 'cpu')
    image_transport = rospy.get_param("~image_transport", 'compressed')
    num_cameras = rospy.get_param("~num_cameras", 1)
    legend = rospy.get_param("~legend", False)
    traversability_labels = rospy.get_param('~traversability_labels', True)

    # Info
    rospy.loginfo('Legend required: %s' % legend)
    rospy.loginfo('Image transport: %s' % image_transport)
    rospy.loginfo('Number of cameras for segmentation: %i' % num_cameras)

    # Draw legend
    if legend:
        f = RELLIS_CONFIG_TRAVERSABILITY if traversability_labels else RELLIS_CONFIG
        data_cfg = yaml.safe_load(open(f, 'r'))
        draw_legend(data_cfg)

    # Create CNNs for image segmentation
    for i in range(num_cameras):
        ImageProcessor(i, image_transport, traversability_labels, device=device)
    rospy.spin()


if __name__ == '__main__':
    main()
