#!/usr/bin/env python
from __future__ import absolute_import, division, print_function
import os
import cv2 as cv
import yaml
import torch
import rospy
import numpy as np
from hrnet.config import config
import matplotlib.pyplot as plt
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
from hrnet.core.function import convert_label, convert_color
from hrnet import models
from hrnet.utils.utils import draw_legend
from traversability_estimation.utils import normalize
from PIL import Image as pil
from time import time
from threading import RLock

pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))
RELLIS_CONFIG = os.path.join(pkg_path, "config/rellis.yaml")
RELLIS_CONFIG_TRAVERSABILITY = os.path.join(pkg_path, "config/rellis_traversability.yaml")
MODEL_CONFIG = os.path.join(pkg_path, "config/hrnet_rellis/"
                                      "seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml")
PRETRAINED_MODEL = os.path.join(pkg_path, "config/weights/"
                                          "seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484/best.pth")
DATASET_ROOT = os.path.join(pkg_path, "data/Rellis_3D/")


class ImageProcessor(object):
    """
    Class for image segmentations

    Args:
        compressed [bool] - for differentiation between compressed and uncompressed image messages
        number [int] - index of the image processor class <0,num_cameras)

    Topics:
        input_{number} - input image topic
        output_{number} - output segmented image topic
    """
    def __init__(self):
        # Read parameters.
        self.num_cameras = rospy.get_param('~num_cameras', 1.0)
        self.image_transport = rospy.get_param('~image_transport', 'compressed')
        self.traversability_labels = rospy.get_param('~traversability_labels', True)
        self.device = rospy.get_param('~device', 'cpu')
        self.dtype = rospy.get_param('~dtype', 'float32')
        assert self.dtype in ('float', 'half')
        self.dtype = eval('torch.%s' % self.dtype)
        self.max_age = rospy.get_param('~max_age', 1.0)
        self.input_size = rospy.get_param('~input_size', None)
        self.input_scale = rospy.get_param('~input_scale', 1.0)
        if self.input_size:
            self.input_size = tuple(self.input_size)
            self.input_scale = 0.0
        else:
            self.input_size = (0, 0)
        assert len(self.input_size) == 2

        self.bridge = CvBridge()
        self.model = self.load_model()
        rospy.loginfo('Loaded HRNet CNN model.')

        # Training mean, std
        self.mean = np.array([0.485, 0.456, 0.406])
        self.std = np.array([0.229, 0.224, 0.225])
        # Running test mean
        self.test_sum = np.zeros((3,))
        self.test_n = 0

        # Draw legend to segmentation
        # TODO: Generic label mapping.
        if self.traversability_labels:
            self.data_cfg = yaml.safe_load(open(RELLIS_CONFIG_TRAVERSABILITY, 'r'))
        else:
            self.data_cfg = yaml.safe_load(open(RELLIS_CONFIG, 'r'))

        # Processing queue: image with camera info for each camera.
        self.lock = RLock()
        self.images = self.num_cameras * [None]
        self.camera_infos = self.num_cameras * [None]
        # Publishers
        self.image_color_pubs = self.num_cameras * [None]
        self.compressed_color_pubs = self.num_cameras * [None]
        self.image_pubs = self.num_cameras * [None]
        self.compressed_pubs = self.num_cameras * [None]
        self.camera_info_pubs = self.num_cameras * [None]
        # Subscribers
        self.image_subs = self.num_cameras * [None]
        self.compressed_subs = self.num_cameras * [None]
        self.camera_info_subs = self.num_cameras * [None]
        for i in range(self.num_cameras):
            # Setup publishers.
            pub = rospy.Publisher('output_%i/semseg_color' % i, Image, queue_size=1)
            self.image_color_pubs[i] = pub
            pub = rospy.Publisher('output_%i/semseg_color/compressed' % i, CompressedImage, queue_size=1)
            self.compressed_color_pubs[i] = pub
            pub = rospy.Publisher('output_%i/semseg' % i, Image, queue_size=1)
            self.image_pubs[i] = pub
            pub = rospy.Publisher('output_%i/semseg/compressed' % i, CompressedImage, queue_size=1)
            self.compressed_pubs[i] = pub
            pub = rospy.Publisher('output_%i/camera_info' % i, CameraInfo, queue_size=1)
            self.camera_info_pubs[i] = pub
            # Setup subscribers.
            if self.image_transport == 'raw':
                sub = rospy.Subscriber('input_%i/image' % i, Image,
                                       lambda msg, i=i: self.callback_color(msg, i), queue_size=1)
            elif self.image_transport == 'compressed':
                sub = rospy.Subscriber('input_%i/image/compressed' % i, CompressedImage,
                                       lambda msg, i=i: self.callback_color(msg, i), queue_size=1)
            self.image_subs[i] = sub
            sub = rospy.Subscriber('input_%i/camera_info' % i, CameraInfo,
                                   lambda msg, i=i: self.get_camera_info(msg, i), queue_size=1)
            self.camera_info_subs[i] = sub
            rospy.loginfo('Publishers and subscribers for camera %i ready.', i)

    def get_camera_info(self, msg, i=None):
        """Store camera calibration for i-th camera."""
        assert isinstance(msg, CameraInfo)
        with self.lock:
            self.camera_infos[i] = msg
        self.camera_info_subs[i].unregister()
        rospy.loginfo('Camera %i (%s) unsubscribed.', i, msg.header.frame_id)

    def load_model(self):
        # Updates PATHS in model config file
        self._update_config(MODEL_CONFIG)

        # Create model
        config.defrost()
        config.merge_from_file(MODEL_CONFIG)
        config.merge_from_list(['TEST.MODEL_FILE', PRETRAINED_MODEL])
        config.freeze()
        model = eval('models.' + config.MODEL.NAME + '.get_seg_model')(config)

        pretrained_dict = torch.load(PRETRAINED_MODEL, map_location='cpu')
        if 'state_dict' in pretrained_dict:
            pretrained_dict = pretrained_dict['state_dict']
        model_dict = model.state_dict()
        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items()
                           if k[6:] in model_dict.keys()}
        model_dict.update(pretrained_dict)
        model.load_state_dict(model_dict)

        model = model.eval()
        model = model.to(device=self.device, dtype=self.dtype)
        return model

    def callback_color(self, img_msg, i=None):
        age = (rospy.Time.now() - img_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Image message is too old for segmentation: %.3f' % age)
            return

        with self.lock:
            self.images[i] = img_msg
            rospy.logdebug('Image updated for camera %i (%s).', i, img_msg.header.frame_id)

        return

    def preprocessing(self, image):
        image = cv.resize(image, self.input_size, fx=self.input_scale, fy=self.input_scale,
                          interpolation=cv.INTER_AREA)
        image = image.astype(np.float32)
        image = image[..., ::-1]  # BGR to RGB
        image = image / 255.0

        # Training data channel-wise mean and std.
        # mean, std = self.mean, self.std

        # Test data intensity mean, image std.
        # self.test_sum += image.mean(axis=(0, 1))
        # self.test_n += 1
        # test_mean = self.test_sum / self.test_n
        # rospy.loginfo('Train mean %s, test mean %s.', self.mean, test_mean)
        # mean = test_mean.mean()
        # std = image.std()

        # Image channel-wise mean and std.
        # mean, std = image.mean(axis=(0, 1)), image.std(axis=(0, 1))

        # Image intensity mean and std.
        # mean, std = image.mean(), image.std()

        # Re-scaled training data mean and std.
        intensity_ratio = image.mean() / self.mean.mean()
        # intensity_ratio = test_mean.mean() / self.mean.mean()
        mean = intensity_ratio * self.mean
        # std = intensity_ratio * self.std
        std = image.std()

        image -= mean
        image /= std

        image = image.transpose((2, 0, 1))  # HxWxC tp CxHxW
        return image

    def process(self, image):
        t0 = time()
        orig_size = (image.shape[1], image.shape[0])
        image = self.preprocessing(image)
        with torch.no_grad():
            input = torch.as_tensor(image).unsqueeze(0)
            input = input.to(device=self.device, dtype=self.dtype)
            pred = self.model(input)
        pred = self.postprocessing(pred, orig_size)
        rospy.logdebug('Image %s processed (%.3f s).', image.shape, time() - t0)
        return pred

    def postprocessing(self, pred, size):
        pred = pred[config.TEST.OUTPUT_INDEX]
        pred = pred.squeeze(0).cpu().numpy()
        pred = np.argmax(pred, axis=0).astype(np.uint8)
        pred = convert_label(pred, True)
        pred = cv.resize(pred, size, interpolation=cv.INTER_NEAREST)
        return pred

    def _update_config(self, config_path):
        assert isinstance(config_path, str)
        with open(config_path, 'r') as f:
            cfg = yaml.safe_load(f)
        cfg['DATASET']['ROOT'] = DATASET_ROOT
        cfg['MODEL']['PRETRAINED'] = PRETRAINED_MODEL
        with open(config_path, 'w') as f:
            yaml.dump(cfg, f)

    def spin(self):
        """Processing loop. Keep processing images in queue until shutdown."""
        i = -1
        while not rospy.is_shutdown():
            t0 = rospy.Time.now()
            i = (i + 1) % len(self.images)
            with self.lock:
                image, camera_info = self.images[i], self.camera_infos[i]
            if not image or not camera_info:
                continue

            try:
                if self.image_transport:
                    arr = self.bridge.compressed_imgmsg_to_cv2(image, "bgr8")
                else:
                    arr = self.bridge.imgmsg_to_cv2(image, "bgr8")
            except CvBridgeError as e:
                rospy.logerr(e)
                raise

            pred = self.process(arr)
            rospy.loginfo('Image %i (%s) processed (%.3f s).',
                          i, image.header.frame_id, (rospy.Time.now() - t0).to_sec())

            if self.compressed_pubs[i].get_num_connections():
                msg = CompressedImage()
                msg.header = image.header
                # msg.format = "png"
                # msg.data = np.array(cv.imencode('.png', pred)[1]).tobytes()
                msg.format = "jpeg"
                msg.data = np.array(cv.imencode('.jpg', pred)[1]).tobytes()
                self.compressed_pubs[i].publish(msg)
            self.camera_info_pubs[i].publish(camera_info)

            if self.compressed_color_pubs[i].get_num_connections():
                pred = convert_color(pred, self.data_cfg["color_map"])
                pred = pred[..., ::-1]  # RGB to BGR
                msg = CompressedImage()
                msg.header = image.header
                msg.format = "jpeg"
                msg.data = np.array(cv.imencode('.jpg', pred)[1]).tobytes()
                self.compressed_color_pubs[i].publish(msg)


def main():
    rospy.init_node('hrnet_inference', log_level=rospy.INFO)

    # Draw legend
    legend = rospy.get_param("~legend", False)
    traversability_labels = rospy.get_param('~traversability_labels', True)
    if legend:
        f = RELLIS_CONFIG_TRAVERSABILITY if traversability_labels else RELLIS_CONFIG
        data_cfg = yaml.safe_load(open(f, 'r'))
        draw_legend(data_cfg)

    node = ImageProcessor()
    node.spin()


if __name__ == '__main__':
    main()
