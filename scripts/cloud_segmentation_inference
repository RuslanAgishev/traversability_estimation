#!/usr/bin/env python

import os
import cv2
from datasets.rellis_3d import SemLaserScan
from traversability_estimation.utils import convert_label
import rospy
from sensor_msgs.msg import Image, PointCloud2
from ros_numpy import msgify, numpify
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured
import torch
import yaml
from threading import RLock


pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))


def msgify_cloud(cloud, frame, stamp, names):
    cloud = unstructured_to_structured(cloud, names=names)
    msg = msgify(PointCloud2, cloud)
    msg.header.frame_id = frame
    msg.header.stamp = stamp
    return msg


class CloudProcessor:
    def __init__(self, cloud_topic='cloud'):
        self.local_map = None
        self.new_map = None
        self.lidar_frame = None
        self.lidar_channels = rospy.get_param('~lidar_channels', 64)
        self.lidar_beams = rospy.get_param('~lidar_beams', 2048)
        self.lidar_fov_up = rospy.get_param('~lidar_fov_up', 22.5)
        self.lidar_fov_down = rospy.get_param('~lidar_fov_down', -22.5)
        self.lock = RLock()

        label_map = rospy.get_param('~label_map', None)
        assert label_map is None or isinstance(label_map, (dict, list))
        if isinstance(label_map, dict):
            label_map = dict((int(k), int(v)) for k, v in label_map.items())
            n = max(label_map) + 1
            self.label_map = np.zeros((n,), dtype=np.uint8)
            for k, v in label_map.items():
                self.label_map[k] = v
        elif isinstance(label_map, list):
            self.label_map = np.asarray(label_map)
        else:
            self.label_map = None
        if self.label_map is not None:
            rospy.loginfo('Label map: %s', self.label_map)

        self.input_pc_fields = rospy.get_param('~input_fields', ['x', 'y', 'z', 'i'])
        self.output_pc_filelds = rospy.get_param('~output_fields', ['x', 'y', 'z', 'r', 'g', 'b', 'obstacle'])
        self.device = rospy.get_param('~device', 'cpu')

        model_weights = rospy.get_param('~weights',
                                        'fcn_resnet50_lr_0.0001_bs_16_epoch_12_Rellis3DClouds_z_depth_iou_0.66.pth')
        self.model_path = os.path.join(pkg_path, "config/weights/", "depth_cloud/%s" % model_weights)
        assert os.path.exists(self.model_path)
        self.model = self.load_model()
        rospy.loginfo('Loaded cloud segmentation model: %s', model_weights)

        self.data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in model_weights]
        if not self.data_fields:
            self.data_fields = ['x', 'y', 'z', 'intensity', 'depth']
        rospy.loginfo('Model takes as input: %s' % ','.join(self.data_fields))

        data_cfg = yaml.safe_load(open(os.path.join(pkg_path, "config/rellis.yaml"), 'r'))
        self.color_map = data_cfg['color_map']
        self.n_classes = len(self.color_map)
        self.scan = SemLaserScan(nclasses=self.n_classes,
                                 sem_color_dict=self.color_map,
                                 project=True,
                                 H=self.lidar_channels, W=self.lidar_beams,
                                 fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)

        # any point that is farer than this threshold from points in existing pcl is considered as new
        self.max_age = rospy.get_param('~max_age', 10.0)

        self.rate = rospy.get_param('~rate', 1.0)
        self.segm_cloud_pub = rospy.Publisher(rospy.get_param('~cloud_out', 'cloud_out'), PointCloud2, queue_size=1)
        self.resized_cloud_pub = rospy.Publisher('resized_cloud', PointCloud2, queue_size=1)
        self.depth_pub = rospy.Publisher('depth', Image, queue_size=1)

        self.cloud_sub = rospy.Subscriber(cloud_topic, PointCloud2, self.segment_cloud_cb)
        rospy.loginfo('Point cloud processing node is ready.')

    def label_to_color(self, label):
        if len(label.shape) == 3:
            C, H, W = label.shape
            label = np.argmax(label, axis=0)
            assert label.shape == (H, W)
        color = self.scan.sem_color_lut[label]
        return color

    def load_model(self):
        model = torch.load(self.model_path, map_location=self.device)
        model = model.eval()
        return model

    def preprocessing(self, cloud):
        C = cloud.shape[-1]
        if len(cloud.shape) == 3:
            H, W, C = cloud.shape

            # Resize if needed.
            # if False and (self.lidar_channels != cloud.shape[0] or self.lidar_beams != cloud.shape[1]):
            if self.lidar_channels != cloud.shape[0] or self.lidar_beams != cloud.shape[1]:
                self.lidar_channels = H
                self.lidar_beams = W
                self.scan = SemLaserScan(nclasses=self.n_classes,
                                         sem_color_dict=self.color_map,
                                         project=True,
                                         H=self.lidar_channels, W=self.lidar_beams,
                                         fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)
                resized = []
                for i in range(cloud.shape[2]):
                    c = cv2.resize(cloud[..., i], (self.lidar_channels, self.lidar_beams),
                                   interpolation=cv2.INTER_LINEAR)
                    resized.append(c)
                resized = np.stack(resized, axis=-1)
                cloud = resized
                rospy.loginfo('Point cloud resized to %s', resized.shape)
                # Publish resized point cloud for debugging.
                resized_struct = unstructured_to_structured(resized, names=self.input_pc_fields)
                resized_msg = msgify(PointCloud2, resized_struct)
                self.resized_cloud_pub.publish(resized_msg)

            cloud = cloud.reshape([H * W, C])
        assert cloud.shape == (self.lidar_channels * self.lidar_beams, C)

        self.scan.set_points(points=cloud[..., 0:3], remissions=cloud[..., 3] if cloud.shape[-1] >= 4 else None)
        # rospy.logdebug('Depth image shape: %s', self.scan.proj_range.shape)
        xyzid = {'x': self.scan.proj_xyz.transpose([2, 0, 1])[0],  # (H x W)
                 'y': self.scan.proj_xyz.transpose([2, 0, 1])[1],  # (H x W)
                 'z': self.scan.proj_xyz.transpose([2, 0, 1])[2],  # (H x W)
                 'intensity': self.scan.proj_remission,            # (H x W)
                 'depth': self.scan.proj_range}                    # (H x W)

        # normalize intensity to be in the same format as in Rellis 3D
        if xyzid['intensity'].max() > 1.0:
            xyzid['intensity'] /= 2**16

        input = np.concatenate([xyzid[f][None] for f in self.data_fields], axis=0)
        rospy.logdebug('Model input shape: %s', input.shape)
        assert input.shape == (len(self.data_fields), self.lidar_channels, self.lidar_beams)

        return input, xyzid

    def model_inference(self, input):
        # Apply inference preprocessing transforms
        batch = torch.from_numpy(input).unsqueeze(0).to(self.device)
        with torch.no_grad():
            pred = self.model(batch)['out']
        rospy.loginfo('Segmented result shape: %s', pred.shape)
        return pred

    def postprocessing(self, pred, xyzid):
        assert isinstance(pred, torch.Tensor)
        assert isinstance(xyzid, np.ndarray) or isinstance(xyzid, dict)
        pred = pred.squeeze(0).cpu().numpy()
        n_classes = pred.shape[0]
        labels = np.argmax(pred, axis=0)

        if isinstance(xyzid, dict):
            xyzid = np.concatenate([xyzid[f][None] for f in xyzid.keys()], axis=0)

        assert labels.max() <= n_classes
        labels = convert_label(labels, inverse=True)
        colors = self.label_to_color(labels)
        # colors_vis = cv2.resize(colors.astype('float'),
        #                         (colors.shape[1] // 2, colors.shape[0] // 2),
        #                         interpolation=cv2.INTER_LINEAR) / colors.max()
        # cv2.imshow('Predicted labels', colors_vis)
        # cv2.waitKey(1)

        assert xyzid.shape[0] >= 3
        assert len(xyzid.shape) == 3  # 5 x H x W
        xyz = xyzid[:3, ...]
        rgb = colors.transpose((2, 0, 1)) / colors.max()  # 3 x H x W
        assert xyz.shape == rgb.shape
        xyzrgb = np.concatenate([xyz, rgb], axis=0)
        C, H, W = xyzrgb.shape
        n_pts = H * W
        xyzrgb = xyzrgb.reshape((C, -1)).T
        assert xyzrgb.shape == (n_pts, C)

        if self.label_map is not None:
            labels = self.label_map[labels]

        labels = labels.reshape((n_pts, 1))
        xyz_rgb_l = np.concatenate([xyzrgb, labels], axis=1)
        assert xyz_rgb_l.shape == (n_pts, C+1)

        rospy.logdebug('XYZ_RGB_L cloud shape: %s', xyz_rgb_l.shape)
        return np.asarray(xyz_rgb_l, dtype=np.float32)

    def segment_cloud_cb(self, pc_msg):
        assert isinstance(pc_msg, PointCloud2)
        self.lidar_frame = pc_msg.header.frame_id

        # Discard old messages.
        msg_stamp = rospy.Time.now()
        age = (msg_stamp - pc_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Discarding points %.1f s > %.1f s old.', age, self.max_age)
            return

        # Transform local map to ground truth localization frame
        cloud = numpify(pc_msg)
        if not set(self.input_pc_fields) <= set(cloud.dtype.names):
            rospy.logwarn('Point cloud does not contain all requested input fields. \nUsing only "x y z".')
            self.input_pc_fields = ['x', 'y', 'z']
        cloud = structured_to_unstructured(cloud[self.input_pc_fields])
        rospy.logdebug('Point cloud of shape %s is received', cloud.shape)

        with self.lock:
            input, xyzid = self.preprocessing(cloud)
            pred = self.model_inference(input)
            xyz_rgb_l = self.postprocessing(pred, xyzid=xyzid)

        # publish segmented point cloud
        stamp = rospy.Time.now()
        segm_pc_msg = msgify_cloud(xyz_rgb_l, frame=self.lidar_frame, stamp=stamp, names=self.output_pc_filelds)
        self.segm_cloud_pub.publish(segm_pc_msg)

        # publish depth image
        power = 16
        depth_img = np.copy(xyzid['depth'])  # depth
        depth_img[depth_img > 0] = depth_img[depth_img > 0] ** (1 / power)
        depth_img[depth_img > 0] = (depth_img[depth_img > 0] - depth_img[depth_img > 0].min()) / \
                                   (depth_img[depth_img > 0].max() - depth_img[depth_img > 0].min())
        depth_msg = msgify(Image, depth_img, '32FC1')
        self.depth_pub.publish(depth_msg)


if __name__ == '__main__':
    rospy.init_node('cloud_segmentation', log_level=rospy.INFO)
    proc = CloudProcessor(cloud_topic=rospy.get_param('~cloud_in', 'cloud_in'))
    rospy.spin()
