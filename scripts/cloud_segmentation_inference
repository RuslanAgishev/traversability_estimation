#!/usr/bin/env python

import os
import cv2
from datasets.rellis_3d import SemLaserScan
from datasets.base_dataset import FLEXIBILITY_LABELS, TRAVERSABILITY_LABELS
from datasets.base_dataset import FLEXIBILITY_COLOR_MAP, TRAVERSABILITY_COLOR_MAP
from traversability_estimation.utils import convert_color
import rospy
from sensor_msgs.msg import Image, PointCloud2
from ros_numpy import msgify, numpify
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured
import torch
from threading import RLock


pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))


def msgify_cloud(cloud, frame, stamp, names):
    assert cloud.ndim == 2
    cloud = unstructured_to_structured(cloud, names=names)
    msg = msgify(PointCloud2, cloud)
    msg.header.frame_id = frame
    msg.header.stamp = stamp
    return msg


class CloudSegmentor:
    def __init__(self, cloud_topic='cloud'):
        self.lidar_frame = None
        self.lidar_channels_H = rospy.get_param('~lidar_channels', 128)
        self.lidar_beams_W = rospy.get_param('~lidar_beams', 1024)
        self.lidar_fov_up = rospy.get_param('~lidar_fov_up', 45.0)
        self.lidar_fov_down = rospy.get_param('~lidar_fov_down', -45.0)
        self.proj_range = np.full((self.lidar_channels_H, self.lidar_beams_W), -1, dtype=np.float32)

        self.device = rospy.get_param('~device', 'cpu')
        self.model_weights = rospy.get_param('~weights')
        self.model_path = os.path.join(pkg_path, "config/weights/", "depth_cloud/%s" % self.model_weights)

        assert os.path.exists(self.model_path)
        self.model = self.load_model()
        rospy.loginfo('Loaded cloud segmentation model: %s', self.model_weights)

        self.data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in self.model_weights]
        if not self.data_fields:
            self.data_fields = ['depth']
        rospy.loginfo('Model takes as input: %s' % ','.join(self.data_fields))
        assert self.data_fields == ['depth']

        self.labels_mapping = None
        if 'traversability' in self.model_weights.lower():
            self.labels_mapping = 'traversability'
        elif 'flexibility' in self.model_weights.lower():
            self.labels_mapping = 'flexibility'
        rospy.loginfo('Model predicts directly traversability labels: %s' % self.labels_mapping)

        self.input_pc_fields = rospy.get_param('~input_fields', ['x', 'y', 'z', 'i'])
        self.output_pc_filelds = rospy.get_param('~output_fields', ['x', 'y', 'z',
                                                                    self.labels_mapping, self.labels_mapping + '_soft'])
        self.trav_threshold = rospy.get_param('~trav_threshold', None)

        assert self.labels_mapping in ['traversability', 'flexibility']

        if self.labels_mapping == 'traversability':
            self.color_map = TRAVERSABILITY_COLOR_MAP
            self.class_values = np.sort([k for k in TRAVERSABILITY_LABELS.keys()]).tolist()
        elif self.labels_mapping == 'flexibility':
            self.color_map = FLEXIBILITY_COLOR_MAP
            self.class_values = np.sort([k for k in FLEXIBILITY_LABELS.keys()]).tolist()

        self.n_classes = len(self.color_map)

        self.scan = SemLaserScan(nclasses=self.n_classes,
                                 sem_color_dict=self.color_map,
                                 project=True,
                                 H=self.lidar_channels_H, W=self.lidar_beams_W,
                                 fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)

        self.lock = RLock()
        # point cloud which time stamp is older is not being processed
        self.max_age = rospy.get_param('~max_age', 0.3)

        self.segm_cloud_pub = rospy.Publisher(rospy.get_param('~cloud_out', 'cloud_out'), PointCloud2, queue_size=1)
        self.segm_cloud_sampled_pub = rospy.Publisher(rospy.get_param('~cloud_out_sampled', 'cloud_out_sampled'), PointCloud2, queue_size=1)
        self.resized_cloud_pub = rospy.Publisher('resized_cloud', PointCloud2, queue_size=1)
        self.depth_pub = rospy.Publisher('depth', Image, queue_size=1)
        self.segm_pub = rospy.Publisher('segmentation', Image, queue_size=1)
        self.debug = rospy.get_param('~debug', False)

        self.cloud_sub = rospy.Subscriber(cloud_topic, PointCloud2, self.segment_cloud_cb)
        rospy.loginfo('Point cloud segmentation node is ready.')

    def load_model(self):
        model = torch.load(self.model_path, map_location=self.device)
        model = model.eval()
        return model

    def preprocessing(self, cloud):
        C = cloud.shape[-1]
        if cloud.ndim == 3:
            H, W, C = cloud.shape

            # Resize if needed.
            # if False and (self.lidar_channels != cloud.shape[0] or self.lidar_beams != cloud.shape[1]):
            if self.lidar_channels_H != cloud.shape[0] or self.lidar_beams_W != cloud.shape[1]:
                self.lidar_channels_H = H
                self.lidar_beams_W = W
                self.scan = SemLaserScan(nclasses=self.n_classes,
                                         sem_color_dict=self.color_map,
                                         project=True,
                                         H=self.lidar_channels_H, W=self.lidar_beams_W,
                                         fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)
                resized = []
                for i in range(cloud.shape[2]):
                    c = cv2.resize(cloud[..., i], (self.lidar_channels_H, self.lidar_beams_W),
                                   interpolation=cv2.INTER_LINEAR)
                    resized.append(c)
                resized = np.stack(resized, axis=-1)
                cloud = resized
                rospy.loginfo('Point cloud resized to %s', resized.shape)

                if self.debug:
                    # Publish resized point cloud for debugging.
                    resized_struct = unstructured_to_structured(resized, names=self.input_pc_fields)
                    resized_msg = msgify(PointCloud2, resized_struct)
                    self.resized_cloud_pub.publish(resized_msg)

            cloud = cloud.reshape([H * W, C])
        assert cloud.shape == (self.lidar_channels_H * self.lidar_beams_W, C)

        self.scan.set_points(points=cloud[..., 0:3])
        self.proj_range = self.scan.proj_range  # only range image as input

        # TODO: rewrite preprocessing with pytorch to run on GPU
        # self.proj_range = np.full((self.lidar_channels_H, self.lidar_beams_W), -1, dtype=np.float32)
        #
        # fov_up = self.lidar_fov_up / 180.0 * np.pi  # field of view up in rad
        # fov_down = self.lidar_fov_down / 180.0 * np.pi  # field of view down in rad
        # fov = abs(fov_down) + abs(fov_up)  # get field of view total in rad
        #
        # depth = np.linalg.norm(cloud[:, :3], ord=2, axis=1)
        #
        # scan_x = cloud[:, 0]
        # scan_y = cloud[:, 1]
        # scan_z = cloud[:, 2]
        #
        # # get angles of all points
        # yaw = -np.arctan2(scan_y, scan_x)
        # pitch = np.arcsin(scan_z / (depth + 1e-8))
        #
        # # get projections in image coords
        # proj_x = 0.5 * (yaw / np.pi + 1.0)  # in [0.0, 1.0]
        # proj_y = 1.0 - (pitch + abs(fov_down)) / fov  # in [0.0, 1.0]
        #
        # # scale to image size using angular resolution
        # proj_x *= self.lidar_beams_W  # in [0.0, W]
        # proj_y *= self.lidar_channels_H  # in [0.0, H]
        #
        # # round and clamp for use as index
        # proj_x = np.floor(proj_x)
        # proj_x = np.minimum(self.lidar_beams_W - 1, proj_x)
        # proj_x = np.maximum(0, proj_x).astype(np.int32)  # in [0,W-1]
        #
        # proj_y = np.floor(proj_y)
        # proj_y = np.minimum(self.lidar_channels_H - 1, proj_y)
        # proj_y = np.maximum(0, proj_y).astype(np.int32)  # in [0,H-1]
        #
        # order = np.argsort(depth)[::-1]
        # depth = depth[order]
        # self.proj_range[proj_y, proj_x] = depth

        rospy.logdebug('Model input shape: %s', self.proj_range.shape)
        assert self.proj_range.shape == (self.lidar_channels_H, self.lidar_beams_W)

        return self.proj_range[None]

    def model_inference(self, input):
        # Apply inference preprocessing transforms
        batch = torch.from_numpy(input).unsqueeze(0).to(self.device)
        with torch.no_grad():
            pred = self.model(batch)['out']
        rospy.loginfo('Segmented result shape: %s', pred.shape)
        return pred

    def postprocessing(self, label_pred, xyz):
        assert isinstance(label_pred, torch.Tensor)
        assert isinstance(xyz, torch.Tensor)
        assert label_pred.device == xyz.device

        label_pred = label_pred.squeeze(0)
        label_pred = torch.log_softmax(label_pred, dim=0)
        label_pred = label_pred

        n_classes, H, W = label_pred.shape
        assert label_pred.ndim == 3

        label_soft = label_pred[1]
        if rospy.has_param('~trav_threshold'):
            label_threshold = label_soft > np.log(rospy.get_param('~trav_threshold'))
        else:
            label_threshold = torch.argmax(label_pred, dim=0)
        label_threshold = torch.as_tensor(label_threshold, dtype=torch.int)
        assert label_threshold.shape == (H, W)

        if self.debug:
            colors = convert_color(label_threshold, self.color_map)
            colors_vis = cv2.resize(colors.cpu().numpy().astype('float'),
                                    (colors.shape[1] // 2, colors.shape[0] // 2),
                                    interpolation=cv2.INTER_LINEAR)
            colors_vis = colors_vis / colors_vis.max()
            segm_msg = msgify(Image, np.uint8(255 * colors_vis), 'rgb8')
            self.segm_pub.publish(segm_msg)

        assert xyz.shape == (self.lidar_channels_H, self.lidar_beams_W, 3)  # H x W x 3
        xyz = xyz.reshape((-1, 3))
        n_pts = xyz.shape[0]

        label_threshold = label_threshold.reshape((n_pts, 1))
        label_soft = label_soft.reshape((n_pts, 1))
        xyz_l_lsoft = torch.concat([xyz, label_threshold, label_soft], dim=1)
        assert xyz_l_lsoft.shape == (n_pts, 5)

        rospy.logdebug('XYZ_L_Lsoft cloud shape: %s', xyz_l_lsoft.shape)

        return torch.as_tensor(xyz_l_lsoft, dtype=torch.float32)

    def segment_cloud_cb(self, pc_msg):
        assert isinstance(pc_msg, PointCloud2)
        self.lidar_frame = pc_msg.header.frame_id

        # Discard old messages.
        msg_stamp = rospy.Time.now()
        age = (msg_stamp - pc_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Discarding points %.1f s > %.1f s old.', age, self.max_age)
            return

        t0 = rospy.Time.now().to_sec()

        # Transform local map to ground truth localization frame
        cloud = numpify(pc_msg)
        if not set(self.input_pc_fields) <= set(cloud.dtype.names):
            rospy.logwarn('Point cloud does not contain all requested input fields. \nUsing only "x y z".')
            self.input_pc_fields = ['x', 'y', 'z']
        cloud = structured_to_unstructured(cloud[self.input_pc_fields])
        rospy.logdebug('Point cloud of shape %s is received', cloud.shape)

        with self.lock:
            input = self.preprocessing(cloud)
            t1 = rospy.Time.now().to_sec()
            rospy.logdebug('Preprocessing took: %.3f [sec]' % (t1 - t0))

            pred = self.model_inference(input)
            t2 = rospy.Time.now().to_sec()
            rospy.logdebug('Model inference took: %.3f [sec]' % (t2 - t1))

            xyz = torch.from_numpy(cloud[..., :3]).to(self.device)
            xyz_l_lsoft = self.postprocessing(pred, xyz=xyz)
            t3 = rospy.Time.now().to_sec()
            rospy.logdebug('Postprocessing took: %.3f [sec]' % (t3 - t2))

            # publish segmented point cloud
            stamp = rospy.Time.now()

            segm_pc_msg = msgify_cloud(xyz_l_lsoft.cpu().numpy(),
                                       frame=self.lidar_frame, stamp=stamp,
                                       names=self.output_pc_filelds)
            self.segm_cloud_pub.publish(segm_pc_msg)

            segm_pc_msg_sampled = msgify_cloud(xyz_l_lsoft.cpu().numpy()[::10],
                                               frame=self.lidar_frame, stamp=stamp,
                                               names=self.output_pc_filelds)
            self.segm_cloud_sampled_pub.publish(segm_pc_msg_sampled)

            if self.debug:
                # publish depth image
                power = 16
                depth_img = np.copy(input[-1])  # depth
                depth_img[depth_img > 0] = depth_img[depth_img > 0] ** (1 / power)
                depth_img[depth_img > 0] = (depth_img[depth_img > 0] - depth_img[depth_img > 0].min()) / \
                                           (depth_img[depth_img > 0].max() - depth_img[depth_img > 0].min())
                depth_msg = msgify(Image, depth_img, '32FC1')
                self.depth_pub.publish(depth_msg)

            t4 = rospy.Time.now().to_sec()
            rospy.logdebug('Data publishing took: %.3f [sec]' % (t4 - t3))

        rospy.loginfo('Point cloud processing time: %.3f [sec]' % (t4 - t0))


if __name__ == '__main__':
    rospy.init_node('cloud_segmentation', log_level=rospy.DEBUG)
    proc = CloudSegmentor(cloud_topic=rospy.get_param('~cloud_in', 'cloud_in'))
    rospy.spin()
