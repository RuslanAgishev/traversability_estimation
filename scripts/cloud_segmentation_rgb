#!/usr/bin/env python

import os
import cv2
from datasets.laserscan import SemLaserScan
from datasets.base_dataset import data_dir
from traversability_estimation.utils import convert_label
import rospy
from sensor_msgs.msg import Image, PointCloud2
from ros_numpy import msgify, numpify
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured
import torch
import yaml
from threading import RLock


pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))


def msgify_cloud(cloud, frame, stamp, names):
    assert cloud.ndim == 2
    cloud = unstructured_to_structured(cloud, names=names)
    msg = msgify(PointCloud2, cloud)
    msg.header.frame_id = frame
    msg.header.stamp = stamp
    return msg


class CloudSegmentor:
    def __init__(self, cloud_topic='cloud'):
        self.lidar_frame = None
        self.lidar_channels = rospy.get_param('~lidar_channels', 128)
        self.lidar_beams = rospy.get_param('~lidar_beams', 1024)
        self.lidar_fov_up = rospy.get_param('~lidar_fov_up', 45.0)
        self.lidar_fov_down = rospy.get_param('~lidar_fov_down', -45.0)
        self.lidar_height_above_ground = rospy.get_param('~lidar_height_above_ground', 0.0)

        self.lock = RLock()
        self.device = rospy.get_param('~device', 'cpu')

        self.model_weights = rospy.get_param('~weights',
                                             'fcn_resnet101_lr_0.0001_bs_16_epoch_5_Rellis3DClouds_intensity_z_depth_iou_0.63.pth')
        self.model_path = os.path.join(pkg_path, "config/weights/", "depth_cloud/%s" % self.model_weights)
        assert os.path.exists(self.model_path)
        self.model = self.load_model()
        rospy.loginfo('Loaded cloud segmentation model: %s', self.model_weights)

        self.data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in self.model_weights]
        if not self.data_fields:
            self.data_fields = ['x', 'y', 'z', 'intensity', 'depth']
        rospy.loginfo('Model takes as input: %s' % ','.join(self.data_fields))

        self.input_pc_fields = rospy.get_param('~input_fields', ['x', 'y', 'z', 'i'])
        self.output_pc_filelds = rospy.get_param('~output_fields', ['x', 'y', 'z', 'r', 'g', 'b'])

        self.dataset = None
        if 'rellis' in self.model_weights.lower():
            self.dataset = 'rellis'
        elif 'semantic' in self.model_weights.lower():
            self.dataset = 'semantickitti19'
        cfg = yaml.safe_load(open(os.path.join(data_dir, "../config/%s.yaml" % self.dataset), 'r'))
        self.color_map = cfg["color_map"]
        self.learning_map = cfg['learning_map']
        self.learning_map_inv = cfg['learning_map_inv']
        self.n_classes = len(self.color_map)

        self.scan = SemLaserScan(nclasses=self.n_classes,
                                 sem_color_dict=self.color_map,
                                 project=True,
                                 H=self.lidar_channels, W=self.lidar_beams,
                                 fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)

        # point cloud which time stamp is older is not being processed
        self.max_age = rospy.get_param('~max_age', 2.0)

        self.rate = rospy.get_param('~rate', 1.0)
        self.segm_cloud_pub = rospy.Publisher(rospy.get_param('~cloud_out', 'cloud_out'), PointCloud2, queue_size=1)
        self.resized_cloud_pub = rospy.Publisher('resized_cloud', PointCloud2, queue_size=1)
        self.depth_pub = rospy.Publisher('depth', Image, queue_size=1)

        self.cloud_sub = rospy.Subscriber(cloud_topic, PointCloud2, self.segment_cloud_cb)
        rospy.loginfo('Point cloud segmentation node is ready.')

    def label_to_color(self, label):
        if len(label.shape) == 3:
            C, H, W = label.shape
            label = np.argmax(label, axis=0)
            assert label.shape == (H, W)
        label = convert_label(label, inverse=False, label_mapping=self.learning_map_inv)
        color = self.scan.sem_color_lut[label]
        return color, label

    def load_model(self):
        model = torch.load(self.model_path, map_location=self.device)
        model = model.eval()
        return model

    def preprocessing(self, cloud):
        C = cloud.shape[-1]
        if len(cloud.shape) == 3:
            H, W, C = cloud.shape

            # Resize if needed.
            # if False and (self.lidar_channels != cloud.shape[0] or self.lidar_beams != cloud.shape[1]):
            if self.lidar_channels != cloud.shape[0] or self.lidar_beams != cloud.shape[1]:
                self.lidar_channels = H
                self.lidar_beams = W
                self.scan = SemLaserScan(nclasses=self.n_classes,
                                         sem_color_dict=self.color_map,
                                         project=True,
                                         H=self.lidar_channels, W=self.lidar_beams,
                                         fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)
                resized = []
                for i in range(cloud.shape[2]):
                    c = cv2.resize(cloud[..., i], (self.lidar_channels, self.lidar_beams),
                                   interpolation=cv2.INTER_LINEAR)
                    resized.append(c)
                resized = np.stack(resized, axis=-1)
                cloud = resized
                rospy.loginfo('Point cloud resized to %s', resized.shape)
                # Publish resized point cloud for debugging.
                resized_struct = unstructured_to_structured(resized, names=self.input_pc_fields)
                resized_msg = msgify(PointCloud2, resized_struct)
                self.resized_cloud_pub.publish(resized_msg)

            cloud = cloud.reshape([H * W, C])
        assert cloud.shape == (self.lidar_channels * self.lidar_beams, C)

        self.scan.set_points(points=cloud[..., 0:3], remissions=cloud[..., 3] if cloud.shape[-1] >= 4 else None)
        # rospy.logdebug('Depth image shape: %s', self.scan.proj_range.shape)
        xyzid = {'x': self.scan.proj_xyz[..., 0],  # (H x W)
                 'y': self.scan.proj_xyz[..., 1],  # (H x W)
                 'z': self.scan.proj_xyz[..., 2],  # (H x W)
                 'intensity': self.scan.proj_remission,            # (H x W)
                 'depth': self.scan.proj_range}                    # (H x W)

        # normalize intensity
        if xyzid['intensity'].max() > 1.0:
            xyzid['intensity'] /= 2.0**16
        
        input = np.concatenate([xyzid[f][None] for f in self.data_fields], axis=0)
        rospy.logdebug('Model input shape: %s', input.shape)
        assert input.shape == (len(self.data_fields), self.lidar_channels, self.lidar_beams)

        return input, xyzid

    def model_inference(self, input):
        # Apply inference preprocessing transforms
        batch = torch.from_numpy(input).unsqueeze(0).to(self.device)
        with torch.no_grad():
            pred = self.model(batch)['out']
        rospy.loginfo('Segmented result shape: %s', pred.shape)
        return pred

    def postprocessing(self, label_pred, xyzid):
        assert isinstance(label_pred, torch.Tensor)
        assert isinstance(xyzid, np.ndarray) or isinstance(xyzid, dict)

        if isinstance(xyzid, dict):
            xyzid = np.concatenate([xyzid[f][None] for f in ['x', 'y', 'z', 'intensity', 'depth']], axis=0)

        label_pred = torch.softmax(label_pred.squeeze(0), dim=0).cpu().numpy()
        # n_classes, H, W = label_pred.shape
        assert label_pred.ndim == 3

        colors, label_pred = self.label_to_color(label_pred)
        assert label_pred.ndim == 2

        colors_vis = cv2.resize(colors.astype('float'),
                                (colors.shape[1] // 2, colors.shape[0] // 2),
                                interpolation=cv2.INTER_LINEAR) / colors.max()
        cv2.imshow('Predicted labels', colors_vis[..., (2, 1, 0)])
        cv2.waitKey(1)

        assert xyzid.shape[0] >= 3
        assert len(xyzid.shape) == 3  # 5 x H x W
        xyz = xyzid[:3, ...]
        rgb = colors.transpose((2, 0, 1)) / colors.max()  # 3 x H x W
        assert xyz.shape == rgb.shape
        xyzrgb = np.concatenate([xyz, rgb], axis=0)
        C, H, W = xyzrgb.shape
        n_pts = H * W
        xyzrgb = xyzrgb.reshape((C, -1)).T
        assert xyzrgb.shape == (n_pts, C)

        label_pred = label_pred.reshape((n_pts, 1))
        xyz_rgb_l = np.concatenate([xyzrgb, label_pred], axis=1)
        assert xyz_rgb_l.shape == (n_pts, C+1)

        rospy.logdebug('XYZ_RGB_L cloud shape: %s', xyz_rgb_l.shape)
        return np.asarray(xyz_rgb_l, dtype=np.float32)

    def segment_cloud_cb(self, pc_msg):
        assert isinstance(pc_msg, PointCloud2)
        self.lidar_frame = pc_msg.header.frame_id

        # Discard old messages.
        msg_stamp = rospy.Time.now()
        age = (msg_stamp - pc_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Discarding points %.1f s > %.1f s old.', age, self.max_age)
            return

        t0 = rospy.Time.now().to_sec()

        # Transform local map to ground truth localization frame
        cloud = numpify(pc_msg)
        if not set(self.input_pc_fields) <= set(cloud.dtype.names):
            rospy.logwarn('Point cloud does not contain all requested input fields. \nUsing only "x y z".')
            self.input_pc_fields = ['x', 'y', 'z']
        cloud = structured_to_unstructured(cloud[self.input_pc_fields])
        rospy.logdebug('Point cloud of shape %s is received', cloud.shape)

        with self.lock:
            input, xyzid = self.preprocessing(cloud)
            t1 = rospy.Time.now().to_sec()
            rospy.logdebug('Preprocessing took: %.3f [sec]' % (t1 - t0))

            pred = self.model_inference(input)
            t2 = rospy.Time.now().to_sec()
            rospy.logdebug('Model inference took: %.3f [sec]' % (t2 - t1))

            xyz_rgb_l = self.postprocessing(pred, xyzid=xyzid)
            t3 = rospy.Time.now().to_sec()
            rospy.logdebug('Postprocessing took: %.3f [sec]' % (t3 - t2))

            # publish segmented point cloud
            stamp = rospy.Time.now()
            segm_pc_msg = msgify_cloud(xyz_rgb_l, frame=self.lidar_frame, stamp=stamp, names=self.output_pc_filelds)
            self.segm_cloud_pub.publish(segm_pc_msg)

            # publish depth image
            power = 16
            depth_img = np.copy(xyzid['depth'])  # depth
            depth_img[depth_img > 0] = depth_img[depth_img > 0] ** (1 / power)
            depth_img[depth_img > 0] = (depth_img[depth_img > 0] - depth_img[depth_img > 0].min()) / \
                                       (depth_img[depth_img > 0].max() - depth_img[depth_img > 0].min())
            depth_msg = msgify(Image, depth_img, '32FC1')
            self.depth_pub.publish(depth_msg)

            t4 = rospy.Time.now().to_sec()
            rospy.logdebug('Data publishing took: %.3f [sec]' % (t4 - t3))

        rospy.loginfo('Point cloud processing time: %.3f [sec]' % (t4 - t0))


if __name__ == '__main__':
    rospy.init_node('cloud_segmentation', log_level=rospy.INFO)
    proc = CloudSegmentor(cloud_topic=rospy.get_param('~cloud_in', 'cloud_in'))
    rospy.spin()
