#!/usr/bin/env python

import datasets
from torch.utils.data import DataLoader
import torch
import segmentation_models_pytorch as smp
from argparse import ArgumentParser


parser = ArgumentParser()
parser.add_argument('--lr', type=float, default=1e-4)
parser.add_argument('--dataset', type=str, default='Rellis3D')
parser.add_argument('--model', type=str, default='Unet')
parser.add_argument('--encoder', type=str, default='resnet34')
parser.add_argument('--encoder_weights', type=str, default='imagenet')
parser.add_argument('--batch_size', type=int, default=1)
parser.add_argument('--img_size', nargs='+', default=(704, 960))
parser.add_argument('--n_epochs', type=int, default=100)
parser.add_argument('--device', type=str, default='cuda')
parser.add_argument('--n_workers', type=int, default=12)
args = parser.parse_args()
args.img_size = tuple(args.img_size)

Dataset = eval('datasets.%s' % args.dataset)
train_dataset = Dataset(crop_size=args.img_size, split='train')
valid_dataset = Dataset(crop_size=args.img_size, split='val')

train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.n_workers)
valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=args.n_workers // 3)

# create segmentation model with pretrained encoder
architecture = eval('smp.%s' % args.model)
model = architecture(
    encoder_name=args.encoder,
    encoder_weights=args.encoder_weights,
    in_channels=3,
    classes=len(train_dataset.class_values),
    activation='sigmoid' if len(train_dataset.class_values) == 1 else 'softmax2d',
)
# model = torch.load('../config/weights/smp/mobilenet_v2_352x640_lr1e-4_iou_0.46.pth')
model = model.train()

# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
loss = smp.utils.losses.DiceLoss()
# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index
metrics = [
    smp.utils.metrics.IoU(threshold=0.5),
]

optimizer = torch.optim.Adam([ 
    dict(params=model.parameters(), lr=args.lr),
])

# create epoch runners 
# it is a simple loop of iterating over dataloader`s samples
train_epoch = smp.utils.train.TrainEpoch(
    model, 
    loss=loss, 
    metrics=metrics, 
    optimizer=optimizer,
    device=args.device,
    verbose=True,
)

valid_epoch = smp.utils.train.ValidEpoch(
    model, 
    loss=loss, 
    metrics=metrics, 
    device=args.device,
    verbose=True,
)

# train model
max_score = 0
for i in range(0, args.n_epochs):
    print('\nEpoch: {}'.format(i))
    train_logs = train_epoch.run(train_loader)
    valid_logs = valid_epoch.run(valid_loader)
    
    # do something (save model, change lr, etc.)
    if max_score < valid_logs['iou_score']:
        max_score = valid_logs['iou_score']
        best_model_name = './%s_%s_%dx%d_lr%g_bs%d_epoch%d_%s_iou_%.2f.pth' %\
                          (args.model, args.encoder, args.img_size[0], args.img_size[1],
                           args.lr, args.batch_size, i, args.dataset, max_score)
        torch.save(model, best_model_name)
        print('Model %s saved!' % best_model_name)
        
    if i == 25:
        optimizer.param_groups[0]['lr'] = args.lr / 10.0
        print('Decrease decoder learning rate!')
