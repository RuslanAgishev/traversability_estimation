#!/usr/bin/env python

import os
import cv2
from datasets.rellis_3d import SemLaserScan
from datasets.base_dataset import FLEXIBILITY_LABELS, TRAVERSABILITY_LABELS
from datasets.base_dataset import FLEXIBILITY_COLOR_MAP, TRAVERSABILITY_COLOR_MAP
from traversability_estimation.utils import convert_color, visualize_cloud
import rospy
from sensor_msgs.msg import Image, PointCloud2
from ros_numpy import msgify, numpify
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured
from timeit import default_timer as timer
import torch
from threading import RLock
import yaml


pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))


class CloudSegmentor:
    def __init__(self, cloud_topic='cloud'):
        self.lidar_frame = None
        self.lidar_channels_H = rospy.get_param('~lidar_channels', 128)
        self.lidar_beams_W = rospy.get_param('~lidar_beams', 1024)
        self.lidar_fov_up = rospy.get_param('~lidar_fov_up', 45.0)
        self.lidar_fov_down = rospy.get_param('~lidar_fov_down', -45.0)
        self.range_projection = rospy.get_param('~range_projection', False)

        self.device = rospy.get_param('~device', 'cpu')

        self.model_output = rospy.get_param('~model_output', 'traversability')
        assert self.model_output in ['traversability', 'flexibility']
        rospy.loginfo('Model predicts %s labels' % self.model_output.upper())

        self.model_weights = rospy.get_param('~%s_weights' % self.model_output)
        self.model_path = os.path.join(pkg_path, "config/weights/", "depth_cloud/%s" % self.model_weights)

        assert os.path.exists(self.model_path)
        self.model = self.load_model()
        rospy.loginfo('Loaded cloud segmentation model: %s', self.model_weights)

        self.data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in self.model_weights]
        if not self.data_fields:
            self.data_fields = ['depth']
        rospy.loginfo('Model takes as input: %s' % ','.join(self.data_fields))
        assert self.data_fields == ['depth']

        self.input_pc_fields = ['x', 'y', 'z']
        self.output_pc_filelds = ['x', 'y', 'z', self.model_output, self.model_output + '_soft']
        self.trav_threshold = rospy.get_param('~trav_threshold', None)

        assert self.model_output in [None, 'traversability', 'flexibility']

        if self.model_output == 'traversability':
            self.color_map = TRAVERSABILITY_COLOR_MAP
            self.class_values = np.sort([k for k in TRAVERSABILITY_LABELS.keys()]).tolist()
        elif self.model_output == 'flexibility':
            self.color_map = FLEXIBILITY_COLOR_MAP
            self.class_values = np.sort([k for k in FLEXIBILITY_LABELS.keys()]).tolist()

        self.n_classes = len(self.color_map)

        self.scan = SemLaserScan(nclasses=self.n_classes,
                                 sem_color_dict=self.color_map,
                                 project=True,
                                 H=self.lidar_channels_H, W=self.lidar_beams_W,
                                 fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)

        self.lock = RLock()
        # point cloud which time stamp is older is not being processed
        self.max_age = rospy.get_param('~max_age', 0.3)

        self.segm_cloud_pub = rospy.Publisher(rospy.get_param('~cloud_out', 'cloud_out'), PointCloud2, queue_size=1)
        self.resized_cloud_pub = rospy.Publisher('resized_cloud', PointCloud2, queue_size=1)
        self.depth_pub = rospy.Publisher('~depth', Image, queue_size=1)
        self.segm_pub = rospy.Publisher('~segmentation', Image, queue_size=1)
        self.debug = rospy.get_param('~debug', False)

        self.cloud_sub = rospy.Subscriber(cloud_topic, PointCloud2, self.segment_cloud_cb)
        rospy.loginfo('Point cloud segmentation node is ready.')

    @staticmethod
    def msgify_cloud(cloud, frame, stamp, names):
        assert cloud.ndim == 2
        cloud = unstructured_to_structured(cloud, names=names)
        msg = msgify(PointCloud2, cloud)
        msg.header.frame_id = frame
        msg.header.stamp = stamp
        return msg

    def load_model(self):
        model = torch.load(self.model_path, map_location=self.device)
        model = model.eval()
        return model

    def label_to_color(self, label):
        if len(label.shape) == 3:
            C, H, W = label.shape
            label = np.argmax(label, axis=0)
            assert label.shape == (H, W)
        color = self.scan.sem_color_lut[label]
        return color

    def preprocessing(self, cloud):
        if self.range_projection:
            if cloud.ndim == 3:
                H, W, C = cloud.shape
                if self.lidar_channels_H != cloud.shape[0] or self.lidar_beams_W != cloud.shape[1]:
                    self.lidar_channels_H, self.lidar_beams_W = H, W
                    self.scan = SemLaserScan(nclasses=self.n_classes,
                                             sem_color_dict=self.color_map,
                                             project=True,
                                             H=H, W=W,
                                             fov_up=self.lidar_fov_up, fov_down=self.lidar_fov_down)
            self.scan.set_points(points=cloud[..., :3].reshape((-1, 3)),
                                 remissions=cloud[..., 3].reshape((-1, 3)) if cloud.shape[-1] >= 4 else None)
            depth = self.scan.proj_range
        else:
            depth = np.linalg.norm(cloud[..., :3], ord=2, axis=-1)

            if cloud.ndim == 2:
                depth = depth.reshape((self.lidar_beams_W, self.lidar_channels_H)).T
            else:
                depth = depth.reshape((self.lidar_channels_H, self.lidar_beams_W))
        # cv2.imshow('Input Depth', depth)
        # cv2.waitKey(1)

        rospy.logdebug('Model input shape: %s', depth.shape)
        assert depth.shape == (self.lidar_channels_H, self.lidar_beams_W)

        return torch.from_numpy(depth[None]).to(self.device)

    def model_inference(self, input):
        # Apply inference preprocessing transforms
        batch = input.unsqueeze(0)
        with torch.no_grad():
            pred = self.model(batch)['out']
        rospy.loginfo('Segmented result shape: %s', pred.shape)
        return pred

    def postprocessing(self, label_pred):
        assert isinstance(label_pred, torch.Tensor)

        label_pred = label_pred.squeeze(0)
        label_pred = torch.log_softmax(label_pred, dim=0)

        assert label_pred.ndim == 3
        n_classes, H, W = label_pred.shape

        label_soft = label_pred[1]
        if rospy.has_param('~trav_threshold'):
            label_threshold = label_soft > torch.log(rospy.get_param('~trav_threshold'))
        else:
            label_threshold = torch.argmax(label_pred, dim=0)
        label_threshold = torch.as_tensor(label_threshold, dtype=torch.float, device=self.device)
        assert label_threshold.shape == label_soft.shape == (H, W)

        if self.debug:
            colors = convert_color(label_threshold, self.color_map)
            colors_vis = cv2.resize(colors.cpu().numpy().astype('float'),
                                    (colors.shape[1] // 2, colors.shape[0] // 2),
                                    interpolation=cv2.INTER_LINEAR)
            colors_vis = colors_vis / colors_vis.max()
            # cv2.imshow('Predicted labels', colors_vis[..., (2, 1, 0)])
            # cv2.waitKey(1)
            segm_msg = msgify(Image, np.uint8(255 * colors_vis), 'rgb8')
            self.segm_pub.publish(segm_msg)

        return label_threshold, label_soft

    def publish(self, cloud, label_th, label_soft, frame, stamp):
        xyz = cloud[..., :3]
        xyz = xyz.reshape([-1, 3], order='F')
        n_pts = self.lidar_channels_H * self.lidar_beams_W
        assert xyz.shape == (n_pts, 3)

        # color = self.label_to_color(np.asarray(label_th.cpu().numpy(), dtype=int))
        # cv2.imshow('Predicted labels', color[..., (2, 1, 0)])
        # cv2.imshow('Predicted labels th', label_th.cpu().numpy())
        # cv2.waitKey(1)
        # visualize_cloud(xyz, color.reshape((-1, 3)))

        label_th = label_th.cpu().numpy().reshape((n_pts, 1), order='F')
        label_soft = label_soft.cpu().numpy().reshape((n_pts, 1), order='F')

        xyz_l_lsoft = np.concatenate([xyz, label_th, label_soft], axis=-1)
        assert xyz_l_lsoft.shape == (n_pts, 5)
        rospy.logdebug('XYZ_L_Lsoft cloud shape: %s', xyz_l_lsoft.shape)

        segm_pc_msg = self.msgify_cloud(xyz_l_lsoft,
                                        frame=frame, stamp=stamp,
                                        names=self.output_pc_filelds)
        self.segm_cloud_pub.publish(segm_pc_msg)

    def segment_cloud_cb(self, pc_msg):
        assert isinstance(pc_msg, PointCloud2)
        self.lidar_frame = pc_msg.header.frame_id

        # Discard old messages.
        age = (rospy.Time.now() - pc_msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Discarding points %.1f s > %.1f s old.', age, self.max_age)
            return

        t0 = timer()

        # Transform local map to ground truth localization frame
        cloud = numpify(pc_msg)
        cloud = structured_to_unstructured(cloud[self.input_pc_fields])
        rospy.logdebug('Point cloud of shape %s is received', cloud.shape)

        with self.lock:
            input = self.preprocessing(cloud)
            t1 = timer()
            rospy.logdebug('Preprocessing took: %.3f [sec]', t1 - t0)

            pred = self.model_inference(input)
            t2 = timer()
            rospy.logdebug('Model inference took: %.3f [sec]', t2 - t1)

            label_th, label_soft = self.postprocessing(pred)
            t3 = timer()
            rospy.logdebug('Postprocessing took: %.3f [sec]', t3 - t2)

            # publish segmented point cloud
            self.publish(cloud, label_th, label_soft, pc_msg.header.frame_id, pc_msg.header.stamp)

            if self.debug:
                # publish depth image
                power = 16
                depth_img = np.copy(input[-1].cpu().numpy())  # depth
                depth_img[depth_img > 0] = depth_img[depth_img > 0] ** (1 / power)
                depth_img[depth_img > 0] = (depth_img[depth_img > 0] - depth_img[depth_img > 0].min()) / \
                                           (depth_img[depth_img > 0].max() - depth_img[depth_img > 0].min())
                depth_msg = msgify(Image, depth_img, '32FC1')
                depth_msg.header = pc_msg.header
                self.depth_pub.publish(depth_msg)

            t4 = timer()
            rospy.logdebug('Data publishing took: %.3f [sec]', t4 - t3)

        rospy.loginfo('Point cloud processing time: %.3f [sec]', t4 - t0)


if __name__ == '__main__':
    rospy.init_node('cloud_segmentation', log_level=rospy.DEBUG)
    proc = CloudSegmentor(cloud_topic=rospy.get_param('~cloud_in', 'cloud_in'))
    rospy.spin()
