#!/usr/bin/env python

import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset, ConcatDataset
import os
from traversability_estimation import show_cloud, normalize, create_model
from traversability_estimation.datasets import TraversabilityDataset
import matplotlib.pyplot as plt
from tqdm import tqdm
from argparse import ArgumentParser

TRAIN_DS_PATHS =\
    ['/home/ruslan/data/bags/traversability/marv/ugv_2022-08-12-16-37-03_trav/os_cloud_node/destaggered_points/',
     '/home/ruslan/data/bags/traversability/marv/ugv_2022-08-12-15-30-22_trav/os_cloud_node/destaggered_points/']
VAL_DS_PATHS =\
    ['/home/ruslan/data/bags/traversability/marv/ugv_2022-08-12-15-18-34_trav/os_cloud_node/destaggered_points/']
IGNORE_LABEL = 255

def str2bool(v):
    return v.lower() in ('1', 'yes', 'true', 't', 'y')

def arg_parser():
    parser = ArgumentParser()
    parser.add_argument('--n-epochs', type=int, default=1)
    parser.add_argument('--learning-rate', type=float, default=1e-3)
    parser.add_argument('--batch-size', type=int, default=8)
    parser.add_argument('--visualize', type=str2bool, default=False)
    parser.add_argument('--train-ds-paths', type=str, nargs='+', default=TRAIN_DS_PATHS)
    parser.add_argument('--val-ds-paths', type=str, default=VAL_DS_PATHS)

    return parser


class Trainer(object):

    def __init__(self, train_dataset, val_dataset, batch_size=2, lr=1e-3, model_arch='deeplabv3_resnet50'):
        self.train_ds = train_dataset
        self.train_dataloader = DataLoader(self.train_ds, batch_size=batch_size, shuffle=True)

        self.val_ds = val_dataset
        self.val_dataloader = DataLoader(self.val_ds, batch_size=1, shuffle=False)

        self.ignore_label = IGNORE_LABEL

        self.device = torch.device('cuda:0')

        self.model_arch = model_arch
        self.model = create_model(self.model_arch, n_inputs=1, n_outputs=1)
        self.model = self.model.to(self.device)

        self.optimizer = torch.optim.Adam(lr=lr, params=self.model.parameters())

        # self.loss_fn = torch.nn.MSELoss(reduction='mean')
        self.loss_fn = torch.nn.CrossEntropyLoss()
        self.min_loss = np.inf
        self.losses = []

    def val_epoch(self):
        val_loss = 0.0
        for i, sample in tqdm(enumerate(self.val_dataloader)):
            # get sample from data loader (depth image, traversability label and points for visualization only)
            depth, label, points = sample
            depth = depth.to(self.device)
            label = label.to(self.device)
            # model inference
            pred = self.model(depth)['out']
            # loss is computed for the part of the prediction where the label is valid
            valid = label != self.ignore_label
            loss = self.loss_fn(pred[valid][None], label[valid][None])
            val_loss += loss.item()
        val_loss /= len(self.val_ds)
        return val_loss

    def train_epoch(self, vis=False):
        train_loss = 0.0
        for i, sample in tqdm(enumerate(self.train_dataloader)):
            # get sample from data loader (depth image, traversability label and points for visualization only)
            depth, label, points = sample
            depth = depth.to(self.device)
            label = label.to(self.device)
            # model inference
            pred = self.model(depth)['out']
            # loss is computed for the part of the prediction where the label is valid
            valid = label != self.ignore_label
            loss = self.loss_fn(pred[valid][None], label[valid][None])

            # backpropagate gradients and update model params
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # print('Iter: %i, training loss: %f' % (i, loss.item()))
            self.losses.append(loss.item())

            if vis and i % 100 == 0:
                visualize(pred, label, depth, ignore_label=self.train_ds.ignore_label)

            train_loss += loss.item()
        train_loss /= len(self.train_ds)
        return train_loss

    def train(self, n_epochs=1, vis=False):
        for e in range(n_epochs):
            print('Training epoch %i...' % e)
            self.model = self.model.train()
            train_loss = self.train_epoch(vis=vis)
            print('Training loss for epoch %i: %f' % (e, train_loss))

            print('Validation epoch %i...'% e)
            self.model = self.model.eval()
            val_loss = self.val_epoch()
            print('Validation loss for epoch %i: %f' % (e, val_loss))

            # decrease learning rate for the next epoch
            # self.optimizer.param_groups[0]['lr'] = self.optimizer.param_groups[0]['lr'] / 2.
            # print('Decreasing learning rate to: %f' % self.optimizer.param_groups[0]['lr'])

            # save better model
            if self.min_loss > train_loss:
                self.min_loss = train_loss
                best_model_name = '%s_loss_%.3f.pth' % (self.model_arch, self.min_loss)
                print("Saving Model:", best_model_name)
                path = os.path.join(os.path.dirname(__file__), 'weights/')
                if not os.path.exists(path):
                    os.makedirs(path)
                torch.save(self.model, os.path.join(path, best_model_name))


def visualize(pred, label, depth_range, points=None,
              ignore_label=IGNORE_LABEL, min_color=None, max_color=None):
    plt.figure(figsize=(20, 10))
    plt.subplot(4, 1, 1)
    plt.title('Prediction')
    pred_vis = torch.clone(pred)
    pred_vis = normalize(pred_vis.detach().cpu())
    plt.imshow(pred_vis[0].squeeze())

    plt.subplot(4, 1, 2)
    plt.title('Masked Prediction')
    pred_vis[label == ignore_label] = 0
    plt.imshow(pred_vis[0].squeeze())

    plt.subplot(4, 1, 3)
    plt.title('Label')
    label_vis = torch.clone(label)
    label_vis = normalize(label_vis.detach().cpu())
    label_vis[label == ignore_label] = 0
    label_vis = label_vis[0].squeeze()
    plt.imshow(label_vis)

    plt.subplot(4, 1, 4)
    plt.title('Range image')
    depth_vis = normalize(torch.clone(depth_range)[0].squeeze().detach().cpu().numpy())
    plt.imshow(depth_vis)

    plt.show()

    if points is not None:
        show_cloud(points, pred[0].squeeze().detach().cpu().numpy().reshape((-1,)), min=min_color, max=max_color)
        # show_cloud(points, label[0].squeeze().detach().cpu().numpy().reshape((-1,)), min=min_color, max=max_color)


def main():
    args = arg_parser().parse_args()
    print(args)

    train_datasets = []
    for path in args.train_ds_paths:
        assert os.path.exists(path), "Training data set path %s is not found" % path
        ds = TraversabilityDataset(path, split='train')
        print('Dataset from %s have %i samples' % (path, len(ds)))
        train_datasets.append(ds)
    train_ds = ConcatDataset(train_datasets)
    print('Train dataset have %i samples' % len(train_ds))

    val_datasets = []
    for path in args.val_ds_paths:
        assert os.path.exists(path), "Validation data set path %s is not found" % path
        ds = TraversabilityDataset(path, split='val')
        print('Dataset from %s have %i samples' % (path, len(ds)))
        val_datasets.append(ds)
    val_ds = ConcatDataset(val_datasets)
    print('Val dataset have %i samples' % len(val_ds))

    # visualize a sample from the data set
    # for i in np.random.choice(range(len(train_ds)), 1):
    #     _ = train_ds.__getitem__(i, visualize=True)
    # for i in np.random.choice(range(len(val_ds)), 1):
    #     _ = val_ds.__getitem__(i, visualize=True)

    # train the model saving the best performing model on validation set
    trainer = Trainer(train_ds, val_ds, batch_size=args.batch_size, lr=args.learning_rate)
    trainer.train(n_epochs=args.n_epochs, vis=args.visualize)

    # test the trained model
    device = torch.device('cpu')
    # model = torch.load('./weights/deeplabv3_resnet50_loss_471770.809.pth', map_location=device)
    # model = torch.load('./weights/deeplabv3_resnet50_loss_0.060.pth', map_location=device)
    model = trainer.model.to(device)
    model = model.eval()

    ds = train_ds
    # ds = val_ds
    for i in np.random.choice(range(len(ds)), 5):
        sample = ds[i]

        depth, label, points = sample
        depth = torch.as_tensor(depth[None]).to(device)
        label = torch.as_tensor(label[None]).to(device)

        with torch.no_grad():
            pred = model(depth)['out']

        valid = label != ds.ignore_label
        print('Predicted traversability range for labeled points: %.3f .. %.3f (mean %3f)' %
              (torch.min(pred[valid]), torch.max(pred[valid]), torch.mean(pred[valid])))
        print('Predicted traversability range: %.3f .. %.3f (mean %3f)' %
              (torch.min(pred), torch.max(pred), torch.mean(pred)))

        # visualize traversability predictions
        # visualize(pred, label, depth, points, min_color=label[valid].min(), max_color=label[valid].max())
        visualize(pred, label, depth, points, min_color=pred[valid].min(), max_color=pred[valid].max())


if __name__ == "__main__":
    main()
