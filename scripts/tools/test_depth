#!/usr/bin/env python

import numpy as np
import torch
from argparse import ArgumentParser
import datasets
import os
from traversability_estimation.utils import correct_label, visualize


def main():
    parser = ArgumentParser()
    parser.add_argument('--dataset', type=str, default='Rellis3DClouds')
    # parser.add_argument('--dataset', type=str, default='TraversabilityClouds')
    parser.add_argument('--device', type=str, default='cpu')
    args = parser.parse_args()
    print(args)

    pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '../../'))

    # Initialize model with the best available weights
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_22_Rellis3DClouds_depth_iou_0.67.pth'
    # model_name = 'fcn_resnet50_lr_0.0001_bs_24_epoch_9_Rellis3DClouds_z_depth_iou_0.61.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_5_Rellis3DClouds_intensity_z_depth_iou_0.63.pth'
    # model_name = 'lraspp_mobilenet_v3_large_lr_0.0001_bs_80_epoch_48_Rellis3DClouds_depth_iou_0.62.pth'
    # model_name = 'fcn_resnet50_lr_0.0001_bs_6_epoch_17_TraversabilityClouds_depth_travTrue_iou_1.00.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_0_Rellis3DClouds_depth_travTrue_iou_0.54.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_0_Rellis3DClouds_depth_travTrue_iou_0.58.pth'
    model_name = 'deeplabv3_resnet101_lr_0.0001_bs_16_epoch_52_Rellis3DClouds_depth_travFalse_iou_0.34.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_40_Rellis3DClouds_z_intensity_depth_travTrue_ftTrue_iou_0.54.pth'
    assert args.dataset in model_name
    model = torch.load(os.path.join(pkg_path, 'config/weights/depth_cloud', model_name), map_location=args.device)
    # model = torch.load(model_name, map_location=args.device)
    model.eval()

    data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in model_name]
    print('Model takes as input: %s' % ','.join(data_fields))

    if 'Traversability' in model_name:
        labels_mapping = 'traversability'
    elif 'Flexibility' in model_name:
        labels_mapping = 'flexibility'
    else:
        labels_mapping = None

    Dataset = eval('datasets.%s' % args.dataset)
    ds = Dataset(split='test', fields=data_fields,
                 labels_mapping=labels_mapping,
                 lidar_beams_step=2 if 'Rellis' in args.dataset else 1)

    for _ in range(5):
        # Apply inference preprocessing transforms
        inpt, label = ds[np.random.choice(range(len(ds)))]

        depth_img = inpt[0]
        power = 16
        depth_img_vis = np.copy(depth_img).squeeze()  # depth
        depth_img_vis[depth_img_vis > 0] = depth_img_vis[depth_img_vis > 0] ** (1 / power)
        depth_img_vis[depth_img_vis > 0] = (depth_img_vis[depth_img_vis > 0] - depth_img_vis[depth_img_vis > 0].min()) / \
                                           (depth_img_vis[depth_img_vis > 0].max() - depth_img_vis[
                                               depth_img_vis > 0].min())

        # Use the model and visualize the prediction
        batch = torch.from_numpy(inpt).unsqueeze(0).to(args.device)
        with torch.no_grad():
            pred = model(batch)['out']
        pred = torch.softmax(pred.squeeze(0), dim=0).cpu().numpy()
        pred = np.argmax(pred, axis=0)

        color_pred = ds.label_to_color(pred)
        color_gt = ds.label_to_color(label)

        # # fix human annotation
        # label_corr = correct_label(label, value_to_correct=11)
        # color_gt_corr = ds.label_to_color(label_corr)
        # # fix human prediction
        # pred_corr = correct_label(pred)
        # color_pred_corr = ds.label_to_color(pred_corr)

        visualize(layout='columns',
                  depth_img=depth_img_vis,
                  prediction=color_pred,
                  # prediction_corr=color_pred_corr,
                  ground_truth=color_gt,
                  # ground_truth_corr=color_gt_corr,
                  )


if __name__ == '__main__':
    main()
