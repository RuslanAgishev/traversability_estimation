#!/usr/bin/env python

import numpy as np
import torch
from argparse import ArgumentParser
from matplotlib import pyplot as plt
import datasets
import os
from traversability_estimation.utils import correct_label


def main():
    parser = ArgumentParser()
    parser.add_argument('--dataset', type=str, default='Rellis3DClouds')
    # parser.add_argument('--dataset', type=str, default='TraversabilityClouds')
    parser.add_argument('--device', type=str, default='cpu')
    args = parser.parse_args()
    print(args)

    pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '../../'))

    # Initialize model with the best available weights
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_22_Rellis3DClouds_depth_iou_0.67.pth'
    # model_name = 'fcn_resnet50_lr_0.0001_bs_24_epoch_9_Rellis3DClouds_z_depth_iou_0.61.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_5_Rellis3DClouds_intensity_z_depth_iou_0.63.pth'
    # model_name = 'lraspp_mobilenet_v3_large_lr_0.0001_bs_80_epoch_48_Rellis3DClouds_depth_iou_0.62.pth'
    # model_name = 'fcn_resnet50_lr_0.0001_bs_6_epoch_17_TraversabilityClouds_depth_travTrue_iou_1.00.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_0_Rellis3DClouds_depth_travTrue_iou_0.54.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_0_Rellis3DClouds_depth_travTrue_iou_0.58.pth'
    model_name = 'deeplabv3_resnet101_lr_0.0001_bs_16_epoch_52_Rellis3DClouds_depth_travFalse_iou_0.34.pth'
    # model_name = 'fcn_resnet101_lr_0.0001_bs_16_epoch_40_Rellis3DClouds_z_intensity_depth_travTrue_ftTrue_iou_0.54.pth'
    assert args.dataset in model_name
    model = torch.load(os.path.join(pkg_path, 'config/weights/depth_cloud', model_name), map_location=args.device)
    # model = torch.load(model_name, map_location=args.device)
    model.eval()

    data_fields = [f[1:-1] for f in ['_x_', '_y_', '_z_', '_intensity_', '_depth_'] if f in model_name]
    print('Model takes as input: %s' % ','.join(data_fields))
    Dataset = eval('datasets.%s' % args.dataset)
    ds = Dataset(split='test', fields=data_fields, traversability_labels='travTrue' in model_name, lidar_beams_step=2)

    for _ in range(5):
        # Apply inference preprocessing transforms
        inpt, label = ds[np.random.choice(range(len(ds)))]

        # fix human annotation
        label_corr = correct_label(label, value_to_correct=11)

        # Use the model and visualize the prediction
        batch = torch.from_numpy(inpt).unsqueeze(0).to(args.device)
        with torch.no_grad():
            pred = model(batch)['out']
        pred = torch.softmax(pred.squeeze(0), dim=0).cpu().numpy()
        pred = np.argmax(pred, axis=0)

        # fix human prediction
        pred_corr = correct_label(pred)

        color_pred = ds.label_to_color(pred)
        color_pred_corr = ds.label_to_color(pred_corr)

        color_gt = ds.label_to_color(label)
        color_gt_corr = ds.label_to_color(label_corr)

        plt.figure(figsize=(20, 10))
        plt.subplot(4, 1, 1)
        plt.imshow(color_pred)
        plt.title('Prediction')
        plt.subplot(4, 1, 2)
        plt.imshow(color_pred_corr)
        plt.title('Prediction: corrected')

        plt.subplot(4, 1, 3)
        plt.imshow(color_gt)
        plt.title('Ground truth')
        plt.subplot(4, 1, 4)
        plt.imshow(color_gt_corr)
        plt.title('Ground truth: corrected')
        plt.tight_layout()
        plt.show()


if __name__ == '__main__':
    main()
