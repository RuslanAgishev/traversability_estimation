#!/usr/bin/env python

import os
import numpy as np
import torchvision.models.segmentation
import torch
from torch.utils.data import DataLoader, BatchSampler
from torch.utils.data.sampler import SequentialSampler
from torch.utils.tensorboard import SummaryWriter
from argparse import ArgumentParser
import datasets
from tqdm import tqdm
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt
from typing import Iterator, List
from time import time


VOID_VALUE = 255


def parse_arguments():
    parser = ArgumentParser()
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--dataset', type=str, default='Rellis3DClouds')
    parser.add_argument('--dataset_fine_tune', type=str, default='TraversabilityClouds_SelfSupervised')
    parser.add_argument('--fine_tune', action='store_true')
    parser.add_argument('--trav_labels', action='store_true')
    parser.add_argument('--dont_save_models', action='store_true')
    parser.add_argument('--architecture', type=str, default='fcn_resnet50')
    parser.add_argument('--batch_size', type=int, default=6)
    parser.add_argument('--n_epochs', type=int, default=100)
    parser.add_argument('--n_workers', type=int, default=os.cpu_count() // 2)
    parser.add_argument('--data_fields', nargs='+', type=str, default=None)
    parser.add_argument('--n_samples', type=int, default=None)
    parser.add_argument('--vis_preds', action='store_true')
    args = parser.parse_args()

    return args


def create_model(architecture, n_inputs, n_outputs, pretrained_backbone=True):
    assert architecture in ['fcn_resnet50', 'fcn_resnet101', 'deeplabv3_resnet50', 'deeplabv3_resnet101',
                            'deeplabv3_mobilenet_v3_large', 'lraspp_mobilenet_v3_large']

    print('Creating model %s with %i inputs and %i outputs' % (architecture, n_inputs, n_outputs))
    Architecture = eval('torchvision.models.segmentation.%s' % architecture)
    model = Architecture(pretrained=pretrained_backbone)

    arch = architecture.split('_')[0]
    encoder = '_'.join(architecture.split('_')[1:])

    # Change input layer to accept n_inputs
    if encoder == 'mobilenet_v3_large':
        model.backbone['0'][0] = torch.nn.Conv2d(n_inputs, 16,
                                                 kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    else:
        model.backbone['conv1'] = torch.nn.Conv2d(n_inputs, 64,
                                                  kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

    # Change final layer to output n classes
    if arch == 'lraspp':
        model.classifier.low_classifier = torch.nn.Conv2d(40, n_outputs, kernel_size=(1, 1), stride=(1, 1))
        model.classifier.high_classifier = torch.nn.Conv2d(128, n_outputs, kernel_size=(1, 1), stride=(1, 1))
    elif arch == 'fcn':
        model.classifier[-1] = torch.nn.Conv2d(512, n_outputs, kernel_size=(1, 1), stride=(1, 1))
    elif arch == 'deeplabv3':
        model.classifier[-1] = torch.nn.Conv2d(256, n_outputs, kernel_size=(1, 1), stride=(1, 1))

    return model


class CommonBatchSampler(BatchSampler):
    """
    Selecting indices from two different datasets to form batches of data
    """
    def __iter__(self) -> Iterator[List[int]]:
        # TODO: add shuffling of indices
        batch = []
        datasets_idx_border = self.sampler.data_source.cumulative_sizes[0]
        for idx in self.sampler:
            batch.append(idx)
            if len(batch) == self.batch_size or idx == datasets_idx_border - 1:
                yield batch
                batch = []
        if len(batch) > 0 and not self.drop_last:
            yield batch


def create_dataloaders(args):
    Dataset = eval('datasets.%s' % args.dataset)
    # lidar_beams_step = 2 in order to have horizontal resolution = 1024 (instead of 2048 as in Rellis data)
    train_dataset = Dataset(split='train', lidar_beams_step=2 if 'Rellis' in args.dataset else None,
                            traversability_labels=args.trav_labels,
                            fields=args.data_fields, num_samples=args.n_samples,
                            labels_mode='labels')
    valid_dataset = Dataset(split='val', lidar_beams_step=2 if 'Rellis' in args.dataset else None,
                            traversability_labels=args.trav_labels,
                            fields=args.data_fields, num_samples=args.n_samples,
                            labels_mode='masks')

    # fine tuning is only supported for traversability labels
    if args.fine_tune:
        assert train_dataset.traversability_labels
        print('Using two datasets for training: %s and %s' % (args.dataset, args.dataset_fine_tune))
        DatasetFT = eval('datasets.%s' % args.dataset_fine_tune)
        ft_dataset_train = DatasetFT(split='train', traversability_labels=args.trav_labels,
                                     fields=args.data_fields, num_samples=args.n_samples,
                                     labels_mode='labels')
        train_dataset_combined = torch.utils.data.ConcatDataset([train_dataset, ft_dataset_train])
        # https://stackoverflow.com/questions/51837110/pytorch-data-loading-from-multiple-different-sized-datasets
        batch_sampler = CommonBatchSampler(SequentialSampler(train_dataset_combined),
                                           batch_size=args.batch_size,
                                           drop_last=False)
        train_loader = DataLoader(dataset=train_dataset_combined,
                                  num_workers=args.n_workers,
                                  batch_sampler=batch_sampler,
                                  pin_memory=True)

        ft_dataset_val = DatasetFT(split='val', traversability_labels=args.trav_labels,
                                   fields=args.data_fields, num_samples=args.n_samples,
                                   labels_mode='masks')
        valid_dataset_combined = torch.utils.data.ConcatDataset([valid_dataset, ft_dataset_val])
        # https://stackoverflow.com/questions/51837110/pytorch-data-loading-from-multiple-different-sized-datasets
        batch_sampler_val = CommonBatchSampler(SequentialSampler(valid_dataset_combined),
                                               batch_size=args.batch_size,
                                               drop_last=False)
        valid_loader = DataLoader(dataset=valid_dataset_combined,
                                  num_workers=args.n_workers,
                                  batch_sampler=batch_sampler_val,
                                  pin_memory=True)
    else:
        train_loader = DataLoader(train_dataset,
                                  batch_size=args.batch_size,
                                  shuffle=True,
                                  num_workers=args.n_workers,
                                  pin_memory=True)

        valid_loader = DataLoader(valid_dataset,
                                  batch_size=1,
                                  shuffle=False,
                                  num_workers=args.n_workers,
                                  pin_memory=True)

    return train_dataset, valid_dataset, train_loader, valid_loader


def main():
    args = parse_arguments()

    train_dataset, valid_dataset, train_loader, valid_loader = create_dataloaders(args)

    # --------------Load and set model and optimizer-------------------------------------
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    # device = torch.device('cpu')

    n_inputs = train_dataset[0][0].shape[0]
    n_outputs = len(train_dataset.class_values)
    print('Model takes as input %i argument: %s' % (n_inputs, str(args.data_fields)))

    model = create_model(args.architecture, n_inputs, n_outputs, pretrained_backbone=False)
    model = model.to(device)

    optimizer = torch.optim.Adam(params=model.parameters(), lr=args.lr)  # Create adam optimizer

    # ----------------Train--------------------------------------------------------------------------
    # Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
    loss_mode = 'multilabel' if train_dataset[0][1].ndim == 3 else 'multiclass'  # (n_cl, H, W) or (H, W)
    print('Loss mode: %s' % loss_mode)
    ignore_label = 0 if not VOID_VALUE in train_dataset.class_values else VOID_VALUE
    print('Ignoring label value: %i' % ignore_label)

    criterion_fn = smp.losses.DiceLoss(mode=loss_mode,
                                       log_loss=True,
                                       from_logits=True,
                                       ignore_index=ignore_label)

    loss_mode_val = 'multilabel' if valid_dataset[0][1].ndim == 3 else 'multiclass'  # (n_cl, H, W) or (H, W)
    criterion_fn_val = smp.losses.DiceLoss(mode=loss_mode_val,
                                           log_loss=True,
                                           from_logits=True)

    # IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index
    background_channel = [0] if not VOID_VALUE in valid_dataset.class_values \
        else [valid_dataset.class_values.index(VOID_VALUE)]
    # background_channel = None
    metric_fn = smp.utils.metrics.IoU(threshold=0.5,
                                      activation='softmax2d',
                                      ignore_channels=background_channel)

    log_dir = '%s_lr_%g_bs_%d_%s_%s_trav%s_ft%s_%s' % \
              (args.architecture, args.lr, args.batch_size, args.dataset, '_'.join(train_dataset.fields),
               train_dataset.traversability_labels, args.fine_tune, time())
    tb_logger = SummaryWriter(log_dir=os.path.join(os.path.dirname(__file__), 'tb_runs', log_dir))

    max_metric = -np.Inf
    for e in tqdm(range(args.n_epochs)):
        print('Starting training epoch %i...' % e)
        # train epoch
        model = model.train()
        for itr, sample in tqdm(enumerate(train_loader)):
            inpt, labels = sample
            inpt, labels = inpt.to(device), labels.to(device)

            pred = model(inpt)['out']  # make prediction

            optimizer.zero_grad()
            loss = criterion_fn(pred, labels.long())  # Calculate loss
            loss.backward()  # Backpropagate loss
            optimizer.step()  # Apply gradient descent change to weight

            tb_logger.add_scalar('Train_Dice_Loss(iter) for Epoch %i' % e, loss.item(), itr)

        print('Train loss at epoch %i: %f' % (e, loss.item()))
        tb_logger.add_scalar('Train_Dice_Loss(epoch)', loss.item(), e)

        print('Validation ...')
        # validation epoch
        metrics = []
        model = model.eval()
        for itr, sample in tqdm(enumerate(valid_loader)):
            inpt, labels = sample
            inpt, labels = inpt.to(device), labels.to(device)

            with torch.no_grad():
                pred = model(inpt)['out']  # make prediction

                assert pred.shape == labels.shape
                metric_sample = metric_fn(pred, labels)
                loss_val = criterion_fn_val(pred, labels.long())

            iou = metric_sample.cpu().numpy()
            metrics.append(iou)

            tb_logger.add_scalar('Valid_mIoU(iter) for Epoch %i' % e, iou, itr)
            tb_logger.add_scalar('Valid_Dice_Loss(iter) for Epoch %i' % e, loss_val.item(), itr)

        metric = np.mean(metrics)

        if not args.dont_save_models:
            # save better model
            if max_metric < metric:  # Save model weights
                max_metric = metric
            if max_metric <= metric or e % 10 == 0:
                name = '%s_lr_%g_bs_%d_epoch_%d_%s_%s_trav%s_iou_%.2f.pth' % \
                   (args.architecture,
                    args.lr, args.batch_size, e, args.dataset, '_'.join(train_dataset.fields),
                    train_dataset.traversability_labels, float(max_metric))
                print("Saving Model:", name)
                torch.save(model, os.path.join(os.path.dirname(__file__), name))

        print('Validation mIoU at epoch %i: %f' % (e, metric))
        tb_logger.add_scalar('Valid_mIoU(epoch)', metric, e)
        tb_logger.add_scalar('Valid_Dice_Loss(epoch)', loss_val.item(), e)

        if e == 60:
            optimizer.param_groups[0]['lr'] /= 10.0
            print('Decrease decoder learning rate to %f !' % optimizer.param_groups[0]['lr'])

        if args.vis_preds:
            # Use the current trained model and visualize a prediction
            model = model.eval()
            inpt, label = valid_dataset[np.random.choice(range(len(valid_dataset)))]
            inpt = torch.from_numpy(inpt[None]).to(device)
            label = torch.from_numpy(label[None]).to(device)

            with torch.no_grad():
                pred = model(inpt)['out']

            pred = pred.squeeze(0).cpu().numpy()
            label = label.squeeze(0).cpu().numpy()

            color_pred = valid_dataset.label_to_color(pred)
            color_gt = valid_dataset.label_to_color(label)

            power = 16
            depth_img = np.copy(inpt.squeeze(0).cpu().numpy()[-1])  # depth
            depth_img[depth_img > 0] = depth_img[depth_img > 0] ** (1 / power)
            depth_img[depth_img > 0] = (depth_img[depth_img > 0] - depth_img[depth_img > 0].min()) / \
                                       (depth_img[depth_img > 0].max() - depth_img[depth_img > 0].min())

            plt.figure(figsize=(20, 10))
            plt.subplot(3, 1, 1)
            plt.imshow(color_pred)
            plt.title('Prediction')
            plt.subplot(3, 1, 2)
            plt.imshow(color_gt)
            plt.title('Ground truth')
            plt.subplot(3, 1, 3)
            plt.imshow(depth_img)
            plt.title('Depth image')
            plt.show()


if __name__ == '__main__':
    main()
