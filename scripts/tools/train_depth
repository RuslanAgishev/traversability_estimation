#!/usr/bin/env python

import os
import numpy as np
import torchvision.models.segmentation
import torch
from torch.utils.data import DataLoader
from argparse import ArgumentParser
import datasets
from tqdm import tqdm
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt


VOID_VALUE = 255


def create_model(architecture, n_inputs, n_outputs, pretrained_backbone=True):
    assert architecture in ['fcn_resnet50', 'fcn_resnet101', 'deeplabv3_resnet50', 'deeplabv3_resnet101',
                            'deeplabv3_mobilenet_v3_large', 'lraspp_mobilenet_v3_large']

    print('Creating model %s with %i inputs and %i outputs' % (architecture, n_inputs, n_outputs))
    Architecture = eval('torchvision.models.segmentation.%s' % architecture)
    model = Architecture(pretrained=pretrained_backbone)

    arch = architecture.split('_')[0]
    encoder = '_'.join(architecture.split('_')[1:])

    # Change input layer to accept n_inputs
    if encoder == 'mobilenet_v3_large':
        model.backbone['0'][0] = torch.nn.Conv2d(n_inputs, 16,
                                                 kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    else:
        model.backbone['conv1'] = torch.nn.Conv2d(n_inputs, 64,
                                                  kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)

    # Change final layer to output n classes
    if arch == 'lraspp':
        model.classifier.low_classifier = torch.nn.Conv2d(40, n_outputs, kernel_size=(1, 1), stride=(1, 1))
        model.classifier.high_classifier = torch.nn.Conv2d(128, n_outputs, kernel_size=(1, 1), stride=(1, 1))
    elif arch == 'fcn':
        model.classifier[-1] = torch.nn.Conv2d(512, n_outputs, kernel_size=(1, 1), stride=(1, 1))
    elif arch == 'deeplabv3':
        model.classifier[-1] = torch.nn.Conv2d(256, n_outputs, kernel_size=(1, 1), stride=(1, 1))

    return model


def main():
    parser = ArgumentParser()
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--dataset', type=str, default='Rellis3DClouds')
    # parser.add_argument('--dataset', type=str, default='TraversabilityClouds')
    parser.add_argument('--trav_labels', action='store_true')
    parser.add_argument('--architecture', type=str, default='fcn_resnet50')
    parser.add_argument('--batch_size', type=int, default=6)
    parser.add_argument('--n_epochs', type=int, default=100)
    parser.add_argument('--n_workers', type=int, default=os.cpu_count() // 2)
    parser.add_argument('--data_fields', nargs='+', type=str, default=None)
    parser.add_argument('--n_samples', type=int, default=None)
    parser.add_argument('--vis_preds', action='store_true')
    args = parser.parse_args()

    Dataset = eval('datasets.%s' % args.dataset)
    # lidar_beams_step = 2 in order to have horizontal resolution = 1024 (instead of 2048 as in Rellis data)
    train_dataset = Dataset(split='train', lidar_beams_step=2 if 'Rellis' in args.dataset else None,
                            traversability_labels=args.trav_labels,
                            fields=args.data_fields, num_samples=args.n_samples)
    valid_dataset = Dataset(split='val', lidar_beams_step=2 if 'Rellis' in args.dataset else None,
                            traversability_labels=args.trav_labels,
                            fields=args.data_fields, num_samples=args.n_samples,
                            labels_mode='masks')

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.n_workers)
    valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=args.n_workers)

    # --------------Load and set model and optimizer-------------------------------------
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    # device = torch.device('cpu')

    n_inputs = train_dataset[0][0].shape[0]
    n_outputs = len(train_dataset.class_values)
    print('Model takes as input %i argument: %s' % (n_inputs, str(args.data_fields)))

    model = create_model(args.architecture, n_inputs, n_outputs, pretrained=False)
    model = model.to(device)

    optimizer = torch.optim.Adam(params=model.parameters(), lr=args.lr)  # Create adam optimizer

    # ----------------Train--------------------------------------------------------------------------
    # Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
    loss_mode = 'multilabel' if train_dataset[0][1].ndim == 3 else 'multiclass'  # (n_cl, H, W) or (H, W)
    criterion_fn = smp.losses.DiceLoss(mode=loss_mode, log_loss=True,
                                       from_logits=True, ignore_index=0 if not VOID_VALUE in train_dataset.class_values \
                                                                        else VOID_VALUE)
    # IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index
    background_channel = [0] if not VOID_VALUE in valid_dataset.class_values \
        else [valid_dataset.class_values.index(VOID_VALUE)]
    # background_channel = None
    metric_fn = smp.utils.metrics.IoU(threshold=0.5,
                                      activation='softmax2d',
                                      ignore_channels=background_channel)

    max_metric = -np.Inf
    for e in tqdm(range(args.n_epochs)):
        # train epoch
        model = model.train()
        for itr, sample in tqdm(enumerate(train_loader)):
            inpt, labels = sample
            inpt, labels = inpt.to(device), labels.to(device)

            pred = model(inpt)['out']  # make prediction

            optimizer.zero_grad()
            loss = criterion_fn(pred, labels.long())  # Calculate loss
            loss.backward()  # Backpropagate loss
            optimizer.step()  # Apply gradient descent change to weight

        # validation epoch
        metrics = []
        model = model.eval()
        for itr, sample in tqdm(enumerate(valid_loader)):
            inpt, labels = sample
            inpt, labels = inpt.to(device), labels.to(device)

            with torch.no_grad():
                pred = model(inpt)['out']  # make prediction

                assert pred.shape == labels.shape
                metric_sample = metric_fn(pred, labels)
            metrics.append(metric_sample.cpu().numpy())

        metric = np.mean(metrics)

        # save better model
        if max_metric < metric or e % 10 == 0:  # Save model weights
            max_metric = metric
            name = '%s_lr_%g_bs_%d_epoch_%d_%s_%s_trav%s_iou_%.2f.pth' % \
                   (args.architecture,
                    args.lr, args.batch_size, e, args.dataset, '_'.join(train_dataset.fields),
                    train_dataset.traversability_labels, float(max_metric))
            print("Saving Model:", name)
            torch.save(model, os.path.join(os.path.dirname(__file__), name))

        print("Epoch: %i" % e)
        print('Train loss: %f' % loss.data.cpu().numpy())
        print('Validation metric: %f' % metric)

        if e == 60:
            optimizer.param_groups[0]['lr'] /= 10.0
            print('Decrease decoder learning rate to %f !' % optimizer.param_groups[0]['lr'])

        if args.vis_preds:
            # Use the current trained model and visualize a prediction
            model = model.eval()
            inpt, label = next(iter(valid_loader))
            with torch.no_grad():
                pred = model(inpt.to(device))['out']
            pred = pred.squeeze(0).cpu().numpy()
            label = label.squeeze(0).cpu().numpy()

            color_pred = valid_dataset.label_to_color(pred)
            color_gt = valid_dataset.label_to_color(label)

            plt.figure(figsize=(20, 10))
            plt.subplot(2, 1, 1)
            plt.imshow(color_pred)
            plt.title('Prediction')
            plt.subplot(2, 1, 2)
            plt.imshow(color_gt)
            plt.title('Ground truth')
            plt.show()


if __name__ == '__main__':
    main()
