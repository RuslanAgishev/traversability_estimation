#!/usr/bin/env python

import os
import numpy as np
import torchvision.models.segmentation
import torch
from torch.utils.data import DataLoader
from argparse import ArgumentParser
import datasets
from tqdm import tqdm
import segmentation_models_pytorch as smp


def main():
    parser = ArgumentParser()
    parser.add_argument('--lr', type=float, default=1e-5)
    parser.add_argument('--dataset', type=str, default='Rellis3DClouds')
    parser.add_argument('--model', type=str, default='fcn')
    parser.add_argument('--encoder', type=str, default='resnet50')
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--n_epochs', type=int, default=100)
    parser.add_argument('--n_workers', type=int, default=os.cpu_count())
    parser.add_argument('--data_fields', nargs='+', type=str, default=None)
    args = parser.parse_args()

    pkg_path = os.path.realpath(os.path.join(os.path.dirname(__file__), '../..'))

    Dataset = eval('datasets.%s' % args.dataset)
    # lidar_beams_step = 2 in order to have horizontal resolution = 1024 (instead of 2048 as in Rellis data)
    train_dataset = Dataset(split='train', lidar_beams_step=2, fields=args.data_fields)
    valid_dataset = Dataset(split='val', lidar_beams_step=2, fields=args.data_fields)

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.n_workers)
    valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=args.n_workers)

    # --------------Load and set model and optimizer-------------------------------------
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    architecture = eval('torchvision.models.segmentation.%s_%s' % (args.model, args.encoder))
    model = architecture(pretrained=False)  # Load net
    # Change input layer to n inputs
    n_inputs = train_dataset[0][0].shape[0]
    model.backbone.conv1 = torch.nn.Conv2d(n_inputs, 64,
                                           kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    n_classes = len(train_dataset.class_values)
    model.classifier[-1] = torch.nn.Conv2d(512, n_classes,
                                           kernel_size=(1, 1), stride=(1, 1))  # Change final layer to n classes
    # model = torch.load(os.path.join(pkg_path, 'config/weights/depth_cloud/fcn_resnet50_legacy.pth'))
    model = model.to(device)
    model = model.train()

    optimizer = torch.optim.Adam(params=model.parameters(), lr=args.lr)  # Create adam optimizer

    # ----------------Train--------------------------------------------------------------------------
    # Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
    # IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index
    criterion_fn = smp.utils.losses.DiceLoss()
    metric_fn = smp.utils.metrics.IoU(threshold=0.5)

    max_metric = -np.Inf
    for e in tqdm(range(args.n_epochs)):
        # train epoch
        for itr, sample in tqdm(enumerate(train_loader)):
            # if itr == 10:
            #     break

            images, labels = sample
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()

            pred = model(images)['out']  # make prediction
            model.zero_grad()

            pred = torch.softmax(pred, dim=1)
            assert pred.min() >= 0.0 and pred.max() <= 1.0

            loss = criterion_fn(pred, labels)  # Calculate loss
            loss.backward()  # Backpropagate loss
            optimizer.step()  # Apply gradient descent change to weight

        # validation epoch
        metrics = []
        for itr, sample in tqdm(enumerate(valid_loader)):
            # if itr == 10:
            #     break

            images, labels = sample
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()

            with torch.no_grad():
                pred = model(images)['out']  # make prediction

                pred = torch.softmax(pred, dim=1)
                assert pred.min() >= 0.0 and pred.max() <= 1.0

                metric1 = metric_fn(pred, labels)  # Calculate loss
            metrics.append(metric1.cpu().numpy())

        metric = np.mean(metrics)

        # save better model
        if max_metric < metric:  # Save model weight
            max_metric = metric
            # name = "%s_%s.pth" % (args.model, args.encoder)
            name = '%s_%s_lr_%g_bs_%d_epoch_%d_%s_%s_iou_%.2f.pth' % \
                   (args.model, args.encoder,
                    args.lr, args.batch_size, e, args.dataset, '_'.join(args.data_fields), float(max_metric))
            print("Saving Model:", name)
            torch.save(model, os.path.join(os.path.dirname(__file__), name))

        print("Epoch: %i" % e)
        print('Train loss: %.3f' % loss.data.cpu().numpy())
        print('Validation metric: %.3f' % metric)


if __name__ == '__main__':
    main()
